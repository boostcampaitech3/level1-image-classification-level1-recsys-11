{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, Compose, CenterCrop, ColorJitter\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = [\n",
    "    \".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\",\n",
    "    \".PNG\", \".ppm\", \".PPM\", \".bmp\", \".BMP\",\n",
    "]\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "\n",
    "class BaseAugmentation:\n",
    "    def __init__(self, resize, mean, std, **args):\n",
    "        self.transform = Compose([\n",
    "            Resize(resize, Image.BILINEAR),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.transform(image)\n",
    "\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    \"\"\"\n",
    "        transform 에 없는 기능들은 이런식으로 __init__, __call__, __repr__ 부분을\n",
    "        직접 구현하여 사용할 수 있습니다.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "\n",
    "class CustomAugmentation:\n",
    "    def __init__(self, resize, mean, std, **args):\n",
    "        self.transform = Compose([\n",
    "            CenterCrop((320, 256)),\n",
    "            Resize(resize, Image.BILINEAR),\n",
    "            ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=mean, std=std),\n",
    "            AddGaussianNoise()\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.transform(image)\n",
    "\n",
    "\n",
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "\n",
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "\n",
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 30:\n",
    "            return cls.YOUNG\n",
    "        elif value < 60:\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskBaseDataset(Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1\": MaskLabels.MASK,\n",
    "        \"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        \"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "    }\n",
    "\n",
    "    # image_paths = []\n",
    "    # mask_labels = []\n",
    "    # gender_labels = []\n",
    "    # age_labels = []\n",
    "\n",
    "    def __init__(self, data_dir, mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246), val_ratio=0.2):\n",
    "        self.data_dir = data_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.val_ratio = val_ratio\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.mask_labels = []\n",
    "        self.gender_labels = []\n",
    "        self.age_labels = []\n",
    "\n",
    "        self.transform = None\n",
    "        self.setup()\n",
    "        self.calc_statistics()\n",
    "\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.data_dir)\n",
    "        for profile in profiles:\n",
    "            if profile.startswith(\".\"):  # \".\" 로 시작하는 파일은 무시합니다\n",
    "                continue\n",
    "\n",
    "            img_folder = os.path.join(self.data_dir, profile)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(self.data_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "\n",
    "                id, gender, race, age = profile.split(\"_\")\n",
    "                gender_label = GenderLabels.from_str(gender)\n",
    "                age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "\n",
    "    def calc_statistics(self):\n",
    "        has_statistics = self.mean is not None and self.std is not None\n",
    "        if not has_statistics:\n",
    "            print(\"[Warning] Calculating statistics... It can take a long time depending on your CPU machine\")\n",
    "            sums = []\n",
    "            squared = []\n",
    "            for image_path in self.image_paths[:3000]:\n",
    "                image = np.array(Image.open(image_path)).astype(np.int32)\n",
    "                sums.append(image.mean(axis=(0, 1)))\n",
    "                squared.append((image ** 2).mean(axis=(0, 1)))\n",
    "\n",
    "            self.mean = np.mean(sums, axis=0) / 255\n",
    "            self.std = (np.mean(squared, axis=0) - self.mean ** 2) ** 0.5 / 255\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert self.transform is not None, \".set_tranform 메소드를 이용하여 transform 을 주입해주세요\"\n",
    "\n",
    "        image = self.read_image(index)\n",
    "        mask_label = self.get_mask_label(index)\n",
    "        gender_label = self.get_gender_label(index)\n",
    "        age_label = self.get_age_label(index)\n",
    "        multi_class_label = self.encode_multi_class(mask_label, gender_label, age_label)\n",
    "\n",
    "        image_transform = self.transform(image)\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def get_mask_label(self, index) -> MaskLabels:\n",
    "        return self.mask_labels[index]\n",
    "\n",
    "    def get_gender_label(self, index) -> GenderLabels:\n",
    "        return self.gender_labels[index]\n",
    "\n",
    "    def get_age_label(self, index) -> AgeLabels:\n",
    "        return self.age_labels[index]\n",
    "\n",
    "    def read_image(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        return Image.open(image_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "        return mask_label * 6 + gender_label * 3 + age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_multi_class(multi_class_label) -> Tuple[MaskLabels, GenderLabels, AgeLabels]:\n",
    "        mask_label = (multi_class_label // 6) % 3\n",
    "        gender_label = (multi_class_label // 3) % 2\n",
    "        age_label = multi_class_label % 3\n",
    "        return mask_label, gender_label, age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def denormalize_image(image, mean, std):\n",
    "        img_cp = image.copy()\n",
    "        img_cp *= std\n",
    "        img_cp += mean\n",
    "        img_cp *= 255.0\n",
    "        img_cp = np.clip(img_cp, 0, 255).astype(np.uint8)\n",
    "        return img_cp\n",
    "\n",
    "    def split_dataset(self) -> Tuple[Subset, Subset]:\n",
    "        \"\"\"\n",
    "        데이터셋을 train 과 val 로 나눕니다,\n",
    "        pytorch 내부의 torch.utils.data.random_split 함수를 사용하여\n",
    "        torch.utils.data.Subset 클래스 둘로 나눕니다.\n",
    "        구현이 어렵지 않으니 구글링 혹은 IDE (e.g. pycharm) 의 navigation 기능을 통해 코드를 한 번 읽어보는 것을 추천드립니다^^\n",
    "        \"\"\"\n",
    "        n_val = int(len(self) * self.val_ratio)\n",
    "        n_train = len(self) - n_val\n",
    "        train_set, val_set = random_split(self, [n_train, n_val])\n",
    "        return train_set, val_set\n",
    "\n",
    "\n",
    "class MaskSplitByProfileDataset(MaskBaseDataset):\n",
    "    \"\"\"\n",
    "        train / val 나누는 기준을 이미지에 대해서 random 이 아닌\n",
    "        사람(profile)을 기준으로 나눕니다.\n",
    "        구현은 val_ratio 에 맞게 train / val 나누는 것을 이미지 전체가 아닌 사람(profile)에 대해서 진행하여 indexing 을 합니다\n",
    "        이후 `split_dataset` 에서 index 에 맞게 Subset 으로 dataset 을 분기합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246), val_ratio=0.2):\n",
    "        self.indices = defaultdict(list)\n",
    "        super().__init__(data_dir, mean, std, val_ratio)\n",
    "\n",
    "    @staticmethod\n",
    "    def _split_profile(profiles, val_ratio):\n",
    "        length = len(profiles)\n",
    "        n_val = int(length * val_ratio)\n",
    "\n",
    "        val_indices = set(random.choices(range(length), k=n_val))\n",
    "        train_indices = set(range(length)) - val_indices\n",
    "        return {\n",
    "            \"train\": train_indices,\n",
    "            \"val\": val_indices\n",
    "        }\n",
    "\n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.data_dir)\n",
    "        profiles = [profile for profile in profiles if not profile.startswith(\".\")]\n",
    "        split_profiles = self._split_profile(profiles, self.val_ratio)\n",
    "\n",
    "        cnt = 0\n",
    "        for phase, indices in split_profiles.items():\n",
    "            for _idx in indices:\n",
    "                profile = profiles[_idx]\n",
    "                img_folder = os.path.join(self.data_dir, profile)\n",
    "                for file_name in os.listdir(img_folder):\n",
    "                    _file_name, ext = os.path.splitext(file_name)\n",
    "                    if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                        continue\n",
    "\n",
    "                    img_path = os.path.join(self.data_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                    mask_label = self._file_names[_file_name]\n",
    "\n",
    "                    id, gender, race, age = profile.split(\"_\")\n",
    "                    gender_label = GenderLabels.from_str(gender)\n",
    "                    age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_labels.append(mask_label)\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "\n",
    "                    self.indices[phase].append(cnt)\n",
    "                    cnt += 1\n",
    "\n",
    "    def split_dataset(self) -> List[Subset]:\n",
    "        return [Subset(self, indices) for phase, indices in self.indices.items()]\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, resize, mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = Compose([\n",
    "            Resize(resize, Image.BILINEAR),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset = MaskBaseDataset(\"/opt/ml/input/data/train/images\")\n",
    "base_dataset.set_transform(BaseAugmentation(resize=(128, 128), mean=(0.5, 0, 0), std=(1,1,1)))\n",
    "train_set, val_set = base_dataset.split_dataset()\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#     train_set,\n",
    "#     batch_size=1000\n",
    "#     # num_workers=\n",
    "#     shuffle=True,\n",
    "#     pin_memory=use_cuda,\n",
    "#     drop_last=True,\n",
    "# )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=100,\n",
    "    #num_workers=multiprocessing.cpu_count()//2,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(-1, 128)\n",
    "        return self.fc(x)\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        self.resnet18.fc = nn.Linear(in_features=512, out_features = num_classes, bias= True) \n",
    "        # self.Linear_1 = nn.Linear(in_features=1000, out_features = num_classes)\n",
    "\n",
    "        # initialize w & b\n",
    "        torch.nn.init.xavier_uniform_(self.resnet18.fc.weight)\n",
    "        stdv = 1/math.sqrt(self.resnet18.fc.in_features)\n",
    "        self.resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        return x\n",
    "\n",
    "# EfficientNet\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import math\n",
    "class EfficientNetB3(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "        # Drop out will be added Here\n",
    "        self.efficientnet._fc = nn.Linear(in_features=1536, out_features = num_classes) \n",
    "        # self.linear = nn.Linear(in_features = self.efficientnet._fc.out_features, out_features = num_classes)\n",
    "\n",
    "        # initialize w & b\n",
    "        torch.nn.init.xavier_uniform_(self.efficientnet._fc.weight)\n",
    "        stdv = 1/math.sqrt(self.efficientnet._fc.in_features)\n",
    "        self.efficientnet._fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.efficientnet(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Custom Model Template\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        1. 위와 같이 생성자의 parameter 에 num_claases 를 포함해주세요.\n",
    "        2. 나만의 모델 아키텍쳐를 디자인 해봅니다.\n",
    "        3. 모델의 output_dimension 은 num_classes 로 설정해주세요.\n",
    "        \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        1. 위에서 정의한 모델 아키텍쳐를 forward propagation 을 진행해주세요\n",
    "        2. 결과로 나온 output 을 return 해주세요\n",
    "        \"\"\"\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetB3(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "        # Drop out will be added Here\n",
    "        in_features = self.efficientnet._fc.in_features\n",
    "        self.efficientnet._fc = nn.Linear(in_features=in_features, out_features = num_classes) \n",
    "        # self.linear = nn.Linear(in_features = self.efficientnet._fc.out_features, out_features = num_classes)\n",
    "\n",
    "        # initialize w & b\n",
    "        torch.nn.init.xavier_uniform_(self.efficientnet._fc.weight)\n",
    "        stdv = 1/math.sqrt(self.efficientnet._fc.in_features)\n",
    "        self.efficientnet._fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.efficientnet(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         ZeroPad2d-1          [-1, 3, 129, 129]               0\n",
      "Conv2dStaticSamePadding-2           [-1, 40, 64, 64]           1,080\n",
      "       BatchNorm2d-3           [-1, 40, 64, 64]              80\n",
      "MemoryEfficientSwish-4           [-1, 40, 64, 64]               0\n",
      "         ZeroPad2d-5           [-1, 40, 66, 66]               0\n",
      "Conv2dStaticSamePadding-6           [-1, 40, 64, 64]             360\n",
      "       BatchNorm2d-7           [-1, 40, 64, 64]              80\n",
      "MemoryEfficientSwish-8           [-1, 40, 64, 64]               0\n",
      "          Identity-9             [-1, 40, 1, 1]               0\n",
      "Conv2dStaticSamePadding-10             [-1, 10, 1, 1]             410\n",
      "MemoryEfficientSwish-11             [-1, 10, 1, 1]               0\n",
      "         Identity-12             [-1, 10, 1, 1]               0\n",
      "Conv2dStaticSamePadding-13             [-1, 40, 1, 1]             440\n",
      "         Identity-14           [-1, 40, 64, 64]               0\n",
      "Conv2dStaticSamePadding-15           [-1, 24, 64, 64]             960\n",
      "      BatchNorm2d-16           [-1, 24, 64, 64]              48\n",
      "      MBConvBlock-17           [-1, 24, 64, 64]               0\n",
      "        ZeroPad2d-18           [-1, 24, 66, 66]               0\n",
      "Conv2dStaticSamePadding-19           [-1, 24, 64, 64]             216\n",
      "      BatchNorm2d-20           [-1, 24, 64, 64]              48\n",
      "MemoryEfficientSwish-21           [-1, 24, 64, 64]               0\n",
      "         Identity-22             [-1, 24, 1, 1]               0\n",
      "Conv2dStaticSamePadding-23              [-1, 6, 1, 1]             150\n",
      "MemoryEfficientSwish-24              [-1, 6, 1, 1]               0\n",
      "         Identity-25              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-26             [-1, 24, 1, 1]             168\n",
      "         Identity-27           [-1, 24, 64, 64]               0\n",
      "Conv2dStaticSamePadding-28           [-1, 24, 64, 64]             576\n",
      "      BatchNorm2d-29           [-1, 24, 64, 64]              48\n",
      "      MBConvBlock-30           [-1, 24, 64, 64]               0\n",
      "         Identity-31           [-1, 24, 64, 64]               0\n",
      "Conv2dStaticSamePadding-32          [-1, 144, 64, 64]           3,456\n",
      "      BatchNorm2d-33          [-1, 144, 64, 64]             288\n",
      "MemoryEfficientSwish-34          [-1, 144, 64, 64]               0\n",
      "        ZeroPad2d-35          [-1, 144, 65, 65]               0\n",
      "Conv2dStaticSamePadding-36          [-1, 144, 32, 32]           1,296\n",
      "      BatchNorm2d-37          [-1, 144, 32, 32]             288\n",
      "MemoryEfficientSwish-38          [-1, 144, 32, 32]               0\n",
      "         Identity-39            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-40              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-41              [-1, 6, 1, 1]               0\n",
      "         Identity-42              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-43            [-1, 144, 1, 1]           1,008\n",
      "         Identity-44          [-1, 144, 32, 32]               0\n",
      "Conv2dStaticSamePadding-45           [-1, 32, 32, 32]           4,608\n",
      "      BatchNorm2d-46           [-1, 32, 32, 32]              64\n",
      "      MBConvBlock-47           [-1, 32, 32, 32]               0\n",
      "         Identity-48           [-1, 32, 32, 32]               0\n",
      "Conv2dStaticSamePadding-49          [-1, 192, 32, 32]           6,144\n",
      "      BatchNorm2d-50          [-1, 192, 32, 32]             384\n",
      "MemoryEfficientSwish-51          [-1, 192, 32, 32]               0\n",
      "        ZeroPad2d-52          [-1, 192, 34, 34]               0\n",
      "Conv2dStaticSamePadding-53          [-1, 192, 32, 32]           1,728\n",
      "      BatchNorm2d-54          [-1, 192, 32, 32]             384\n",
      "MemoryEfficientSwish-55          [-1, 192, 32, 32]               0\n",
      "         Identity-56            [-1, 192, 1, 1]               0\n",
      "Conv2dStaticSamePadding-57              [-1, 8, 1, 1]           1,544\n",
      "MemoryEfficientSwish-58              [-1, 8, 1, 1]               0\n",
      "         Identity-59              [-1, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-60            [-1, 192, 1, 1]           1,728\n",
      "         Identity-61          [-1, 192, 32, 32]               0\n",
      "Conv2dStaticSamePadding-62           [-1, 32, 32, 32]           6,144\n",
      "      BatchNorm2d-63           [-1, 32, 32, 32]              64\n",
      "      MBConvBlock-64           [-1, 32, 32, 32]               0\n",
      "         Identity-65           [-1, 32, 32, 32]               0\n",
      "Conv2dStaticSamePadding-66          [-1, 192, 32, 32]           6,144\n",
      "      BatchNorm2d-67          [-1, 192, 32, 32]             384\n",
      "MemoryEfficientSwish-68          [-1, 192, 32, 32]               0\n",
      "        ZeroPad2d-69          [-1, 192, 34, 34]               0\n",
      "Conv2dStaticSamePadding-70          [-1, 192, 32, 32]           1,728\n",
      "      BatchNorm2d-71          [-1, 192, 32, 32]             384\n",
      "MemoryEfficientSwish-72          [-1, 192, 32, 32]               0\n",
      "         Identity-73            [-1, 192, 1, 1]               0\n",
      "Conv2dStaticSamePadding-74              [-1, 8, 1, 1]           1,544\n",
      "MemoryEfficientSwish-75              [-1, 8, 1, 1]               0\n",
      "         Identity-76              [-1, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-77            [-1, 192, 1, 1]           1,728\n",
      "         Identity-78          [-1, 192, 32, 32]               0\n",
      "Conv2dStaticSamePadding-79           [-1, 32, 32, 32]           6,144\n",
      "      BatchNorm2d-80           [-1, 32, 32, 32]              64\n",
      "      MBConvBlock-81           [-1, 32, 32, 32]               0\n",
      "         Identity-82           [-1, 32, 32, 32]               0\n",
      "Conv2dStaticSamePadding-83          [-1, 192, 32, 32]           6,144\n",
      "      BatchNorm2d-84          [-1, 192, 32, 32]             384\n",
      "MemoryEfficientSwish-85          [-1, 192, 32, 32]               0\n",
      "        ZeroPad2d-86          [-1, 192, 36, 36]               0\n",
      "Conv2dStaticSamePadding-87          [-1, 192, 16, 16]           4,800\n",
      "      BatchNorm2d-88          [-1, 192, 16, 16]             384\n",
      "MemoryEfficientSwish-89          [-1, 192, 16, 16]               0\n",
      "         Identity-90            [-1, 192, 1, 1]               0\n",
      "Conv2dStaticSamePadding-91              [-1, 8, 1, 1]           1,544\n",
      "MemoryEfficientSwish-92              [-1, 8, 1, 1]               0\n",
      "         Identity-93              [-1, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-94            [-1, 192, 1, 1]           1,728\n",
      "         Identity-95          [-1, 192, 16, 16]               0\n",
      "Conv2dStaticSamePadding-96           [-1, 48, 16, 16]           9,216\n",
      "      BatchNorm2d-97           [-1, 48, 16, 16]              96\n",
      "      MBConvBlock-98           [-1, 48, 16, 16]               0\n",
      "         Identity-99           [-1, 48, 16, 16]               0\n",
      "Conv2dStaticSamePadding-100          [-1, 288, 16, 16]          13,824\n",
      "     BatchNorm2d-101          [-1, 288, 16, 16]             576\n",
      "MemoryEfficientSwish-102          [-1, 288, 16, 16]               0\n",
      "       ZeroPad2d-103          [-1, 288, 20, 20]               0\n",
      "Conv2dStaticSamePadding-104          [-1, 288, 16, 16]           7,200\n",
      "     BatchNorm2d-105          [-1, 288, 16, 16]             576\n",
      "MemoryEfficientSwish-106          [-1, 288, 16, 16]               0\n",
      "        Identity-107            [-1, 288, 1, 1]               0\n",
      "Conv2dStaticSamePadding-108             [-1, 12, 1, 1]           3,468\n",
      "MemoryEfficientSwish-109             [-1, 12, 1, 1]               0\n",
      "        Identity-110             [-1, 12, 1, 1]               0\n",
      "Conv2dStaticSamePadding-111            [-1, 288, 1, 1]           3,744\n",
      "        Identity-112          [-1, 288, 16, 16]               0\n",
      "Conv2dStaticSamePadding-113           [-1, 48, 16, 16]          13,824\n",
      "     BatchNorm2d-114           [-1, 48, 16, 16]              96\n",
      "     MBConvBlock-115           [-1, 48, 16, 16]               0\n",
      "        Identity-116           [-1, 48, 16, 16]               0\n",
      "Conv2dStaticSamePadding-117          [-1, 288, 16, 16]          13,824\n",
      "     BatchNorm2d-118          [-1, 288, 16, 16]             576\n",
      "MemoryEfficientSwish-119          [-1, 288, 16, 16]               0\n",
      "       ZeroPad2d-120          [-1, 288, 20, 20]               0\n",
      "Conv2dStaticSamePadding-121          [-1, 288, 16, 16]           7,200\n",
      "     BatchNorm2d-122          [-1, 288, 16, 16]             576\n",
      "MemoryEfficientSwish-123          [-1, 288, 16, 16]               0\n",
      "        Identity-124            [-1, 288, 1, 1]               0\n",
      "Conv2dStaticSamePadding-125             [-1, 12, 1, 1]           3,468\n",
      "MemoryEfficientSwish-126             [-1, 12, 1, 1]               0\n",
      "        Identity-127             [-1, 12, 1, 1]               0\n",
      "Conv2dStaticSamePadding-128            [-1, 288, 1, 1]           3,744\n",
      "        Identity-129          [-1, 288, 16, 16]               0\n",
      "Conv2dStaticSamePadding-130           [-1, 48, 16, 16]          13,824\n",
      "     BatchNorm2d-131           [-1, 48, 16, 16]              96\n",
      "     MBConvBlock-132           [-1, 48, 16, 16]               0\n",
      "        Identity-133           [-1, 48, 16, 16]               0\n",
      "Conv2dStaticSamePadding-134          [-1, 288, 16, 16]          13,824\n",
      "     BatchNorm2d-135          [-1, 288, 16, 16]             576\n",
      "MemoryEfficientSwish-136          [-1, 288, 16, 16]               0\n",
      "       ZeroPad2d-137          [-1, 288, 17, 17]               0\n",
      "Conv2dStaticSamePadding-138            [-1, 288, 8, 8]           2,592\n",
      "     BatchNorm2d-139            [-1, 288, 8, 8]             576\n",
      "MemoryEfficientSwish-140            [-1, 288, 8, 8]               0\n",
      "        Identity-141            [-1, 288, 1, 1]               0\n",
      "Conv2dStaticSamePadding-142             [-1, 12, 1, 1]           3,468\n",
      "MemoryEfficientSwish-143             [-1, 12, 1, 1]               0\n",
      "        Identity-144             [-1, 12, 1, 1]               0\n",
      "Conv2dStaticSamePadding-145            [-1, 288, 1, 1]           3,744\n",
      "        Identity-146            [-1, 288, 8, 8]               0\n",
      "Conv2dStaticSamePadding-147             [-1, 96, 8, 8]          27,648\n",
      "     BatchNorm2d-148             [-1, 96, 8, 8]             192\n",
      "     MBConvBlock-149             [-1, 96, 8, 8]               0\n",
      "        Identity-150             [-1, 96, 8, 8]               0\n",
      "Conv2dStaticSamePadding-151            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-152            [-1, 576, 8, 8]           1,152\n",
      "MemoryEfficientSwish-153            [-1, 576, 8, 8]               0\n",
      "       ZeroPad2d-154          [-1, 576, 10, 10]               0\n",
      "Conv2dStaticSamePadding-155            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-156            [-1, 576, 8, 8]           1,152\n",
      "MemoryEfficientSwish-157            [-1, 576, 8, 8]               0\n",
      "        Identity-158            [-1, 576, 1, 1]               0\n",
      "Conv2dStaticSamePadding-159             [-1, 24, 1, 1]          13,848\n",
      "MemoryEfficientSwish-160             [-1, 24, 1, 1]               0\n",
      "        Identity-161             [-1, 24, 1, 1]               0\n",
      "Conv2dStaticSamePadding-162            [-1, 576, 1, 1]          14,400\n",
      "        Identity-163            [-1, 576, 8, 8]               0\n",
      "Conv2dStaticSamePadding-164             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-165             [-1, 96, 8, 8]             192\n",
      "     MBConvBlock-166             [-1, 96, 8, 8]               0\n",
      "        Identity-167             [-1, 96, 8, 8]               0\n",
      "Conv2dStaticSamePadding-168            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-169            [-1, 576, 8, 8]           1,152\n",
      "MemoryEfficientSwish-170            [-1, 576, 8, 8]               0\n",
      "       ZeroPad2d-171          [-1, 576, 10, 10]               0\n",
      "Conv2dStaticSamePadding-172            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-173            [-1, 576, 8, 8]           1,152\n",
      "MemoryEfficientSwish-174            [-1, 576, 8, 8]               0\n",
      "        Identity-175            [-1, 576, 1, 1]               0\n",
      "Conv2dStaticSamePadding-176             [-1, 24, 1, 1]          13,848\n",
      "MemoryEfficientSwish-177             [-1, 24, 1, 1]               0\n",
      "        Identity-178             [-1, 24, 1, 1]               0\n",
      "Conv2dStaticSamePadding-179            [-1, 576, 1, 1]          14,400\n",
      "        Identity-180            [-1, 576, 8, 8]               0\n",
      "Conv2dStaticSamePadding-181             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-182             [-1, 96, 8, 8]             192\n",
      "     MBConvBlock-183             [-1, 96, 8, 8]               0\n",
      "        Identity-184             [-1, 96, 8, 8]               0\n",
      "Conv2dStaticSamePadding-185            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-186            [-1, 576, 8, 8]           1,152\n",
      "MemoryEfficientSwish-187            [-1, 576, 8, 8]               0\n",
      "       ZeroPad2d-188          [-1, 576, 10, 10]               0\n",
      "Conv2dStaticSamePadding-189            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-190            [-1, 576, 8, 8]           1,152\n",
      "MemoryEfficientSwish-191            [-1, 576, 8, 8]               0\n",
      "        Identity-192            [-1, 576, 1, 1]               0\n",
      "Conv2dStaticSamePadding-193             [-1, 24, 1, 1]          13,848\n",
      "MemoryEfficientSwish-194             [-1, 24, 1, 1]               0\n",
      "        Identity-195             [-1, 24, 1, 1]               0\n",
      "Conv2dStaticSamePadding-196            [-1, 576, 1, 1]          14,400\n",
      "        Identity-197            [-1, 576, 8, 8]               0\n",
      "Conv2dStaticSamePadding-198             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-199             [-1, 96, 8, 8]             192\n",
      "     MBConvBlock-200             [-1, 96, 8, 8]               0\n",
      "        Identity-201             [-1, 96, 8, 8]               0\n",
      "Conv2dStaticSamePadding-202            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-203            [-1, 576, 8, 8]           1,152\n",
      "MemoryEfficientSwish-204            [-1, 576, 8, 8]               0\n",
      "       ZeroPad2d-205          [-1, 576, 10, 10]               0\n",
      "Conv2dStaticSamePadding-206            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-207            [-1, 576, 8, 8]           1,152\n",
      "MemoryEfficientSwish-208            [-1, 576, 8, 8]               0\n",
      "        Identity-209            [-1, 576, 1, 1]               0\n",
      "Conv2dStaticSamePadding-210             [-1, 24, 1, 1]          13,848\n",
      "MemoryEfficientSwish-211             [-1, 24, 1, 1]               0\n",
      "        Identity-212             [-1, 24, 1, 1]               0\n",
      "Conv2dStaticSamePadding-213            [-1, 576, 1, 1]          14,400\n",
      "        Identity-214            [-1, 576, 8, 8]               0\n",
      "Conv2dStaticSamePadding-215             [-1, 96, 8, 8]          55,296\n",
      "     BatchNorm2d-216             [-1, 96, 8, 8]             192\n",
      "     MBConvBlock-217             [-1, 96, 8, 8]               0\n",
      "        Identity-218             [-1, 96, 8, 8]               0\n",
      "Conv2dStaticSamePadding-219            [-1, 576, 8, 8]          55,296\n",
      "     BatchNorm2d-220            [-1, 576, 8, 8]           1,152\n",
      "MemoryEfficientSwish-221            [-1, 576, 8, 8]               0\n",
      "       ZeroPad2d-222          [-1, 576, 12, 12]               0\n",
      "Conv2dStaticSamePadding-223            [-1, 576, 8, 8]          14,400\n",
      "     BatchNorm2d-224            [-1, 576, 8, 8]           1,152\n",
      "MemoryEfficientSwish-225            [-1, 576, 8, 8]               0\n",
      "        Identity-226            [-1, 576, 1, 1]               0\n",
      "Conv2dStaticSamePadding-227             [-1, 24, 1, 1]          13,848\n",
      "MemoryEfficientSwish-228             [-1, 24, 1, 1]               0\n",
      "        Identity-229             [-1, 24, 1, 1]               0\n",
      "Conv2dStaticSamePadding-230            [-1, 576, 1, 1]          14,400\n",
      "        Identity-231            [-1, 576, 8, 8]               0\n",
      "Conv2dStaticSamePadding-232            [-1, 136, 8, 8]          78,336\n",
      "     BatchNorm2d-233            [-1, 136, 8, 8]             272\n",
      "     MBConvBlock-234            [-1, 136, 8, 8]               0\n",
      "        Identity-235            [-1, 136, 8, 8]               0\n",
      "Conv2dStaticSamePadding-236            [-1, 816, 8, 8]         110,976\n",
      "     BatchNorm2d-237            [-1, 816, 8, 8]           1,632\n",
      "MemoryEfficientSwish-238            [-1, 816, 8, 8]               0\n",
      "       ZeroPad2d-239          [-1, 816, 12, 12]               0\n",
      "Conv2dStaticSamePadding-240            [-1, 816, 8, 8]          20,400\n",
      "     BatchNorm2d-241            [-1, 816, 8, 8]           1,632\n",
      "MemoryEfficientSwish-242            [-1, 816, 8, 8]               0\n",
      "        Identity-243            [-1, 816, 1, 1]               0\n",
      "Conv2dStaticSamePadding-244             [-1, 34, 1, 1]          27,778\n",
      "MemoryEfficientSwish-245             [-1, 34, 1, 1]               0\n",
      "        Identity-246             [-1, 34, 1, 1]               0\n",
      "Conv2dStaticSamePadding-247            [-1, 816, 1, 1]          28,560\n",
      "        Identity-248            [-1, 816, 8, 8]               0\n",
      "Conv2dStaticSamePadding-249            [-1, 136, 8, 8]         110,976\n",
      "     BatchNorm2d-250            [-1, 136, 8, 8]             272\n",
      "     MBConvBlock-251            [-1, 136, 8, 8]               0\n",
      "        Identity-252            [-1, 136, 8, 8]               0\n",
      "Conv2dStaticSamePadding-253            [-1, 816, 8, 8]         110,976\n",
      "     BatchNorm2d-254            [-1, 816, 8, 8]           1,632\n",
      "MemoryEfficientSwish-255            [-1, 816, 8, 8]               0\n",
      "       ZeroPad2d-256          [-1, 816, 12, 12]               0\n",
      "Conv2dStaticSamePadding-257            [-1, 816, 8, 8]          20,400\n",
      "     BatchNorm2d-258            [-1, 816, 8, 8]           1,632\n",
      "MemoryEfficientSwish-259            [-1, 816, 8, 8]               0\n",
      "        Identity-260            [-1, 816, 1, 1]               0\n",
      "Conv2dStaticSamePadding-261             [-1, 34, 1, 1]          27,778\n",
      "MemoryEfficientSwish-262             [-1, 34, 1, 1]               0\n",
      "        Identity-263             [-1, 34, 1, 1]               0\n",
      "Conv2dStaticSamePadding-264            [-1, 816, 1, 1]          28,560\n",
      "        Identity-265            [-1, 816, 8, 8]               0\n",
      "Conv2dStaticSamePadding-266            [-1, 136, 8, 8]         110,976\n",
      "     BatchNorm2d-267            [-1, 136, 8, 8]             272\n",
      "     MBConvBlock-268            [-1, 136, 8, 8]               0\n",
      "        Identity-269            [-1, 136, 8, 8]               0\n",
      "Conv2dStaticSamePadding-270            [-1, 816, 8, 8]         110,976\n",
      "     BatchNorm2d-271            [-1, 816, 8, 8]           1,632\n",
      "MemoryEfficientSwish-272            [-1, 816, 8, 8]               0\n",
      "       ZeroPad2d-273          [-1, 816, 12, 12]               0\n",
      "Conv2dStaticSamePadding-274            [-1, 816, 8, 8]          20,400\n",
      "     BatchNorm2d-275            [-1, 816, 8, 8]           1,632\n",
      "MemoryEfficientSwish-276            [-1, 816, 8, 8]               0\n",
      "        Identity-277            [-1, 816, 1, 1]               0\n",
      "Conv2dStaticSamePadding-278             [-1, 34, 1, 1]          27,778\n",
      "MemoryEfficientSwish-279             [-1, 34, 1, 1]               0\n",
      "        Identity-280             [-1, 34, 1, 1]               0\n",
      "Conv2dStaticSamePadding-281            [-1, 816, 1, 1]          28,560\n",
      "        Identity-282            [-1, 816, 8, 8]               0\n",
      "Conv2dStaticSamePadding-283            [-1, 136, 8, 8]         110,976\n",
      "     BatchNorm2d-284            [-1, 136, 8, 8]             272\n",
      "     MBConvBlock-285            [-1, 136, 8, 8]               0\n",
      "        Identity-286            [-1, 136, 8, 8]               0\n",
      "Conv2dStaticSamePadding-287            [-1, 816, 8, 8]         110,976\n",
      "     BatchNorm2d-288            [-1, 816, 8, 8]           1,632\n",
      "MemoryEfficientSwish-289            [-1, 816, 8, 8]               0\n",
      "       ZeroPad2d-290          [-1, 816, 12, 12]               0\n",
      "Conv2dStaticSamePadding-291            [-1, 816, 8, 8]          20,400\n",
      "     BatchNorm2d-292            [-1, 816, 8, 8]           1,632\n",
      "MemoryEfficientSwish-293            [-1, 816, 8, 8]               0\n",
      "        Identity-294            [-1, 816, 1, 1]               0\n",
      "Conv2dStaticSamePadding-295             [-1, 34, 1, 1]          27,778\n",
      "MemoryEfficientSwish-296             [-1, 34, 1, 1]               0\n",
      "        Identity-297             [-1, 34, 1, 1]               0\n",
      "Conv2dStaticSamePadding-298            [-1, 816, 1, 1]          28,560\n",
      "        Identity-299            [-1, 816, 8, 8]               0\n",
      "Conv2dStaticSamePadding-300            [-1, 136, 8, 8]         110,976\n",
      "     BatchNorm2d-301            [-1, 136, 8, 8]             272\n",
      "     MBConvBlock-302            [-1, 136, 8, 8]               0\n",
      "        Identity-303            [-1, 136, 8, 8]               0\n",
      "Conv2dStaticSamePadding-304            [-1, 816, 8, 8]         110,976\n",
      "     BatchNorm2d-305            [-1, 816, 8, 8]           1,632\n",
      "MemoryEfficientSwish-306            [-1, 816, 8, 8]               0\n",
      "       ZeroPad2d-307          [-1, 816, 12, 12]               0\n",
      "Conv2dStaticSamePadding-308            [-1, 816, 4, 4]          20,400\n",
      "     BatchNorm2d-309            [-1, 816, 4, 4]           1,632\n",
      "MemoryEfficientSwish-310            [-1, 816, 4, 4]               0\n",
      "        Identity-311            [-1, 816, 1, 1]               0\n",
      "Conv2dStaticSamePadding-312             [-1, 34, 1, 1]          27,778\n",
      "MemoryEfficientSwish-313             [-1, 34, 1, 1]               0\n",
      "        Identity-314             [-1, 34, 1, 1]               0\n",
      "Conv2dStaticSamePadding-315            [-1, 816, 1, 1]          28,560\n",
      "        Identity-316            [-1, 816, 4, 4]               0\n",
      "Conv2dStaticSamePadding-317            [-1, 232, 4, 4]         189,312\n",
      "     BatchNorm2d-318            [-1, 232, 4, 4]             464\n",
      "     MBConvBlock-319            [-1, 232, 4, 4]               0\n",
      "        Identity-320            [-1, 232, 4, 4]               0\n",
      "Conv2dStaticSamePadding-321           [-1, 1392, 4, 4]         322,944\n",
      "     BatchNorm2d-322           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-323           [-1, 1392, 4, 4]               0\n",
      "       ZeroPad2d-324           [-1, 1392, 8, 8]               0\n",
      "Conv2dStaticSamePadding-325           [-1, 1392, 4, 4]          34,800\n",
      "     BatchNorm2d-326           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-327           [-1, 1392, 4, 4]               0\n",
      "        Identity-328           [-1, 1392, 1, 1]               0\n",
      "Conv2dStaticSamePadding-329             [-1, 58, 1, 1]          80,794\n",
      "MemoryEfficientSwish-330             [-1, 58, 1, 1]               0\n",
      "        Identity-331             [-1, 58, 1, 1]               0\n",
      "Conv2dStaticSamePadding-332           [-1, 1392, 1, 1]          82,128\n",
      "        Identity-333           [-1, 1392, 4, 4]               0\n",
      "Conv2dStaticSamePadding-334            [-1, 232, 4, 4]         322,944\n",
      "     BatchNorm2d-335            [-1, 232, 4, 4]             464\n",
      "     MBConvBlock-336            [-1, 232, 4, 4]               0\n",
      "        Identity-337            [-1, 232, 4, 4]               0\n",
      "Conv2dStaticSamePadding-338           [-1, 1392, 4, 4]         322,944\n",
      "     BatchNorm2d-339           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-340           [-1, 1392, 4, 4]               0\n",
      "       ZeroPad2d-341           [-1, 1392, 8, 8]               0\n",
      "Conv2dStaticSamePadding-342           [-1, 1392, 4, 4]          34,800\n",
      "     BatchNorm2d-343           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-344           [-1, 1392, 4, 4]               0\n",
      "        Identity-345           [-1, 1392, 1, 1]               0\n",
      "Conv2dStaticSamePadding-346             [-1, 58, 1, 1]          80,794\n",
      "MemoryEfficientSwish-347             [-1, 58, 1, 1]               0\n",
      "        Identity-348             [-1, 58, 1, 1]               0\n",
      "Conv2dStaticSamePadding-349           [-1, 1392, 1, 1]          82,128\n",
      "        Identity-350           [-1, 1392, 4, 4]               0\n",
      "Conv2dStaticSamePadding-351            [-1, 232, 4, 4]         322,944\n",
      "     BatchNorm2d-352            [-1, 232, 4, 4]             464\n",
      "     MBConvBlock-353            [-1, 232, 4, 4]               0\n",
      "        Identity-354            [-1, 232, 4, 4]               0\n",
      "Conv2dStaticSamePadding-355           [-1, 1392, 4, 4]         322,944\n",
      "     BatchNorm2d-356           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-357           [-1, 1392, 4, 4]               0\n",
      "       ZeroPad2d-358           [-1, 1392, 8, 8]               0\n",
      "Conv2dStaticSamePadding-359           [-1, 1392, 4, 4]          34,800\n",
      "     BatchNorm2d-360           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-361           [-1, 1392, 4, 4]               0\n",
      "        Identity-362           [-1, 1392, 1, 1]               0\n",
      "Conv2dStaticSamePadding-363             [-1, 58, 1, 1]          80,794\n",
      "MemoryEfficientSwish-364             [-1, 58, 1, 1]               0\n",
      "        Identity-365             [-1, 58, 1, 1]               0\n",
      "Conv2dStaticSamePadding-366           [-1, 1392, 1, 1]          82,128\n",
      "        Identity-367           [-1, 1392, 4, 4]               0\n",
      "Conv2dStaticSamePadding-368            [-1, 232, 4, 4]         322,944\n",
      "     BatchNorm2d-369            [-1, 232, 4, 4]             464\n",
      "     MBConvBlock-370            [-1, 232, 4, 4]               0\n",
      "        Identity-371            [-1, 232, 4, 4]               0\n",
      "Conv2dStaticSamePadding-372           [-1, 1392, 4, 4]         322,944\n",
      "     BatchNorm2d-373           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-374           [-1, 1392, 4, 4]               0\n",
      "       ZeroPad2d-375           [-1, 1392, 8, 8]               0\n",
      "Conv2dStaticSamePadding-376           [-1, 1392, 4, 4]          34,800\n",
      "     BatchNorm2d-377           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-378           [-1, 1392, 4, 4]               0\n",
      "        Identity-379           [-1, 1392, 1, 1]               0\n",
      "Conv2dStaticSamePadding-380             [-1, 58, 1, 1]          80,794\n",
      "MemoryEfficientSwish-381             [-1, 58, 1, 1]               0\n",
      "        Identity-382             [-1, 58, 1, 1]               0\n",
      "Conv2dStaticSamePadding-383           [-1, 1392, 1, 1]          82,128\n",
      "        Identity-384           [-1, 1392, 4, 4]               0\n",
      "Conv2dStaticSamePadding-385            [-1, 232, 4, 4]         322,944\n",
      "     BatchNorm2d-386            [-1, 232, 4, 4]             464\n",
      "     MBConvBlock-387            [-1, 232, 4, 4]               0\n",
      "        Identity-388            [-1, 232, 4, 4]               0\n",
      "Conv2dStaticSamePadding-389           [-1, 1392, 4, 4]         322,944\n",
      "     BatchNorm2d-390           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-391           [-1, 1392, 4, 4]               0\n",
      "       ZeroPad2d-392           [-1, 1392, 8, 8]               0\n",
      "Conv2dStaticSamePadding-393           [-1, 1392, 4, 4]          34,800\n",
      "     BatchNorm2d-394           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-395           [-1, 1392, 4, 4]               0\n",
      "        Identity-396           [-1, 1392, 1, 1]               0\n",
      "Conv2dStaticSamePadding-397             [-1, 58, 1, 1]          80,794\n",
      "MemoryEfficientSwish-398             [-1, 58, 1, 1]               0\n",
      "        Identity-399             [-1, 58, 1, 1]               0\n",
      "Conv2dStaticSamePadding-400           [-1, 1392, 1, 1]          82,128\n",
      "        Identity-401           [-1, 1392, 4, 4]               0\n",
      "Conv2dStaticSamePadding-402            [-1, 232, 4, 4]         322,944\n",
      "     BatchNorm2d-403            [-1, 232, 4, 4]             464\n",
      "     MBConvBlock-404            [-1, 232, 4, 4]               0\n",
      "        Identity-405            [-1, 232, 4, 4]               0\n",
      "Conv2dStaticSamePadding-406           [-1, 1392, 4, 4]         322,944\n",
      "     BatchNorm2d-407           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-408           [-1, 1392, 4, 4]               0\n",
      "       ZeroPad2d-409           [-1, 1392, 6, 6]               0\n",
      "Conv2dStaticSamePadding-410           [-1, 1392, 4, 4]          12,528\n",
      "     BatchNorm2d-411           [-1, 1392, 4, 4]           2,784\n",
      "MemoryEfficientSwish-412           [-1, 1392, 4, 4]               0\n",
      "        Identity-413           [-1, 1392, 1, 1]               0\n",
      "Conv2dStaticSamePadding-414             [-1, 58, 1, 1]          80,794\n",
      "MemoryEfficientSwish-415             [-1, 58, 1, 1]               0\n",
      "        Identity-416             [-1, 58, 1, 1]               0\n",
      "Conv2dStaticSamePadding-417           [-1, 1392, 1, 1]          82,128\n",
      "        Identity-418           [-1, 1392, 4, 4]               0\n",
      "Conv2dStaticSamePadding-419            [-1, 384, 4, 4]         534,528\n",
      "     BatchNorm2d-420            [-1, 384, 4, 4]             768\n",
      "     MBConvBlock-421            [-1, 384, 4, 4]               0\n",
      "        Identity-422            [-1, 384, 4, 4]               0\n",
      "Conv2dStaticSamePadding-423           [-1, 2304, 4, 4]         884,736\n",
      "     BatchNorm2d-424           [-1, 2304, 4, 4]           4,608\n",
      "MemoryEfficientSwish-425           [-1, 2304, 4, 4]               0\n",
      "       ZeroPad2d-426           [-1, 2304, 6, 6]               0\n",
      "Conv2dStaticSamePadding-427           [-1, 2304, 4, 4]          20,736\n",
      "     BatchNorm2d-428           [-1, 2304, 4, 4]           4,608\n",
      "MemoryEfficientSwish-429           [-1, 2304, 4, 4]               0\n",
      "        Identity-430           [-1, 2304, 1, 1]               0\n",
      "Conv2dStaticSamePadding-431             [-1, 96, 1, 1]         221,280\n",
      "MemoryEfficientSwish-432             [-1, 96, 1, 1]               0\n",
      "        Identity-433             [-1, 96, 1, 1]               0\n",
      "Conv2dStaticSamePadding-434           [-1, 2304, 1, 1]         223,488\n",
      "        Identity-435           [-1, 2304, 4, 4]               0\n",
      "Conv2dStaticSamePadding-436            [-1, 384, 4, 4]         884,736\n",
      "     BatchNorm2d-437            [-1, 384, 4, 4]             768\n",
      "     MBConvBlock-438            [-1, 384, 4, 4]               0\n",
      "        Identity-439            [-1, 384, 4, 4]               0\n",
      "Conv2dStaticSamePadding-440           [-1, 1536, 4, 4]         589,824\n",
      "     BatchNorm2d-441           [-1, 1536, 4, 4]           3,072\n",
      "MemoryEfficientSwish-442           [-1, 1536, 4, 4]               0\n",
      "AdaptiveAvgPool2d-443           [-1, 1536, 1, 1]               0\n",
      "         Dropout-444                 [-1, 1536]               0\n",
      "          Linear-445                 [-1, 1000]       1,537,000\n",
      "================================================================\n",
      "Total params: 12,233,232\n",
      "Trainable params: 12,233,232\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 138.29\n",
      "Params size (MB): 46.67\n",
      "Estimated Total Size (MB): 185.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "EffNet = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "EffNet\n",
    "import torchsummary \n",
    "torchsummary.summary(EffNet, (3, 128, 128), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (_conv_stem): Conv2dStaticSamePadding(\n",
      "    3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
      "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "  )\n",
      "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_blocks): ModuleList(\n",
      "    (0): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (1): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (2): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (3): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (4): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (5): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (6): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (7): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (8): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (9): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (10): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (11): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (12): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (13): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (14): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (15): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (16): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (17): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (18): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (19): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (20): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (21): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (22): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (23): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (24): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (25): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "  )\n",
      "  (_conv_head): Conv2dStaticSamePadding(\n",
      "    384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "    (static_padding): Identity()\n",
      "  )\n",
      "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "  (_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (_fc): Linear(in_features=1536, out_features=1000, bias=True)\n",
      "  (_swish): MemoryEfficientSwish()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(EffNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_vit import ViT\n",
    "model = ViT('B_16_imagenet1k', pretrained=True)\n",
    "\n",
    "class ViTPretrainedFreeze(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = ViT('B_16_imagenet1k', pretrained=True)\n",
    "        \n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features=in_features, out_features= num_classes, bias= True)\n",
    "\n",
    "        # initialize\n",
    "        torch.nn.init.xavier_uniform_(self.model.fc.weight)\n",
    "        stdv = 1/math.sqrt(self.model.fc.in_features)\n",
    "        self.model.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "model = ViT('B_16_imagenet1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 18% |\n"
     ]
    }
   ],
   "source": [
    "# !pip install GPUtil\n",
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (226) must match the size of tensor b (577) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/baseLineTest.ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/baseLineTest.ipynb#ch0000014vscode-remote?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m ViTPretrainedFreeze(\u001b[39m18\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/baseLineTest.ipynb#ch0000014vscode-remote?line=1'>2</a>\u001b[0m model(torch\u001b[39m.\u001b[39;49mTensor(np\u001b[39m.\u001b[39;49mones((\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m244\u001b[39;49m, \u001b[39m244\u001b[39;49m))))\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=724'>725</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=725'>726</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=726'>727</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=727'>728</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=728'>729</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=729'>730</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=730'>731</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/baseLineTest.ipynb Cell 9'\u001b[0m in \u001b[0;36mViTPretrainedFreeze.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/baseLineTest.ipynb#ch0000006vscode-remote?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/baseLineTest.ipynb#ch0000006vscode-remote?line=20'>21</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/baseLineTest.ipynb#ch0000006vscode-remote?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=724'>725</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=725'>726</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=726'>727</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=727'>728</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=728'>729</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=729'>730</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=730'>731</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/pytorch_pretrained_vit/model.py:164\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/pytorch_pretrained_vit/model.py?line=161'>162</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_token\u001b[39m.\u001b[39mexpand(b, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), x), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# b,gh*gw+1,d\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/pytorch_pretrained_vit/model.py?line=162'>163</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpositional_embedding\u001b[39m\u001b[39m'\u001b[39m): \n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/pytorch_pretrained_vit/model.py?line=163'>164</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpositional_embedding(x)  \u001b[39m# b,gh*gw+1,d \u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/pytorch_pretrained_vit/model.py?line=164'>165</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(x)  \u001b[39m# b,gh*gw+1,d\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/pytorch_pretrained_vit/model.py?line=165'>166</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpre_logits\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=724'>725</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=725'>726</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=726'>727</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=727'>728</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=728'>729</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=729'>730</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=730'>731</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/pytorch_pretrained_vit/model.py:24\u001b[0m, in \u001b[0;36mPositionalEmbedding1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.venv/lib/python3.8/site-packages/pytorch_pretrained_vit/model.py?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='file:///~/.venv/lib/python3.8/site-packages/pytorch_pretrained_vit/model.py?line=22'>23</a>\u001b[0m     \u001b[39m\"\"\"Input has shape `(batch_size, seq_len, emb_dim)`\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///~/.venv/lib/python3.8/site-packages/pytorch_pretrained_vit/model.py?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_embedding\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (226) must match the size of tensor b (577) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ViTPretrainedFreeze(18)\n",
    "model(torch.Tensor(np.ones((1, 3, 244, 244)))).squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 384, 384])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(torch.Tensor(np.ones((2, 3,384, 384)))).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 24, 24]         590,592\n",
      "PositionalEmbedding1D-2             [-1, 577, 768]               0\n",
      "         LayerNorm-3             [-1, 577, 768]           1,536\n",
      "            Linear-4             [-1, 577, 768]         590,592\n",
      "            Linear-5             [-1, 577, 768]         590,592\n",
      "            Linear-6             [-1, 577, 768]         590,592\n",
      "           Dropout-7         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-8             [-1, 577, 768]               0\n",
      "            Linear-9             [-1, 577, 768]         590,592\n",
      "          Dropout-10             [-1, 577, 768]               0\n",
      "        LayerNorm-11             [-1, 577, 768]           1,536\n",
      "           Linear-12            [-1, 577, 3072]       2,362,368\n",
      "           Linear-13             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-14             [-1, 577, 768]               0\n",
      "          Dropout-15             [-1, 577, 768]               0\n",
      "            Block-16             [-1, 577, 768]               0\n",
      "        LayerNorm-17             [-1, 577, 768]           1,536\n",
      "           Linear-18             [-1, 577, 768]         590,592\n",
      "           Linear-19             [-1, 577, 768]         590,592\n",
      "           Linear-20             [-1, 577, 768]         590,592\n",
      "          Dropout-21         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-22             [-1, 577, 768]               0\n",
      "           Linear-23             [-1, 577, 768]         590,592\n",
      "          Dropout-24             [-1, 577, 768]               0\n",
      "        LayerNorm-25             [-1, 577, 768]           1,536\n",
      "           Linear-26            [-1, 577, 3072]       2,362,368\n",
      "           Linear-27             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-28             [-1, 577, 768]               0\n",
      "          Dropout-29             [-1, 577, 768]               0\n",
      "            Block-30             [-1, 577, 768]               0\n",
      "        LayerNorm-31             [-1, 577, 768]           1,536\n",
      "           Linear-32             [-1, 577, 768]         590,592\n",
      "           Linear-33             [-1, 577, 768]         590,592\n",
      "           Linear-34             [-1, 577, 768]         590,592\n",
      "          Dropout-35         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-36             [-1, 577, 768]               0\n",
      "           Linear-37             [-1, 577, 768]         590,592\n",
      "          Dropout-38             [-1, 577, 768]               0\n",
      "        LayerNorm-39             [-1, 577, 768]           1,536\n",
      "           Linear-40            [-1, 577, 3072]       2,362,368\n",
      "           Linear-41             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-42             [-1, 577, 768]               0\n",
      "          Dropout-43             [-1, 577, 768]               0\n",
      "            Block-44             [-1, 577, 768]               0\n",
      "        LayerNorm-45             [-1, 577, 768]           1,536\n",
      "           Linear-46             [-1, 577, 768]         590,592\n",
      "           Linear-47             [-1, 577, 768]         590,592\n",
      "           Linear-48             [-1, 577, 768]         590,592\n",
      "          Dropout-49         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-50             [-1, 577, 768]               0\n",
      "           Linear-51             [-1, 577, 768]         590,592\n",
      "          Dropout-52             [-1, 577, 768]               0\n",
      "        LayerNorm-53             [-1, 577, 768]           1,536\n",
      "           Linear-54            [-1, 577, 3072]       2,362,368\n",
      "           Linear-55             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-56             [-1, 577, 768]               0\n",
      "          Dropout-57             [-1, 577, 768]               0\n",
      "            Block-58             [-1, 577, 768]               0\n",
      "        LayerNorm-59             [-1, 577, 768]           1,536\n",
      "           Linear-60             [-1, 577, 768]         590,592\n",
      "           Linear-61             [-1, 577, 768]         590,592\n",
      "           Linear-62             [-1, 577, 768]         590,592\n",
      "          Dropout-63         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-64             [-1, 577, 768]               0\n",
      "           Linear-65             [-1, 577, 768]         590,592\n",
      "          Dropout-66             [-1, 577, 768]               0\n",
      "        LayerNorm-67             [-1, 577, 768]           1,536\n",
      "           Linear-68            [-1, 577, 3072]       2,362,368\n",
      "           Linear-69             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-70             [-1, 577, 768]               0\n",
      "          Dropout-71             [-1, 577, 768]               0\n",
      "            Block-72             [-1, 577, 768]               0\n",
      "        LayerNorm-73             [-1, 577, 768]           1,536\n",
      "           Linear-74             [-1, 577, 768]         590,592\n",
      "           Linear-75             [-1, 577, 768]         590,592\n",
      "           Linear-76             [-1, 577, 768]         590,592\n",
      "          Dropout-77         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-78             [-1, 577, 768]               0\n",
      "           Linear-79             [-1, 577, 768]         590,592\n",
      "          Dropout-80             [-1, 577, 768]               0\n",
      "        LayerNorm-81             [-1, 577, 768]           1,536\n",
      "           Linear-82            [-1, 577, 3072]       2,362,368\n",
      "           Linear-83             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-84             [-1, 577, 768]               0\n",
      "          Dropout-85             [-1, 577, 768]               0\n",
      "            Block-86             [-1, 577, 768]               0\n",
      "        LayerNorm-87             [-1, 577, 768]           1,536\n",
      "           Linear-88             [-1, 577, 768]         590,592\n",
      "           Linear-89             [-1, 577, 768]         590,592\n",
      "           Linear-90             [-1, 577, 768]         590,592\n",
      "          Dropout-91         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-92             [-1, 577, 768]               0\n",
      "           Linear-93             [-1, 577, 768]         590,592\n",
      "          Dropout-94             [-1, 577, 768]               0\n",
      "        LayerNorm-95             [-1, 577, 768]           1,536\n",
      "           Linear-96            [-1, 577, 3072]       2,362,368\n",
      "           Linear-97             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-98             [-1, 577, 768]               0\n",
      "          Dropout-99             [-1, 577, 768]               0\n",
      "           Block-100             [-1, 577, 768]               0\n",
      "       LayerNorm-101             [-1, 577, 768]           1,536\n",
      "          Linear-102             [-1, 577, 768]         590,592\n",
      "          Linear-103             [-1, 577, 768]         590,592\n",
      "          Linear-104             [-1, 577, 768]         590,592\n",
      "         Dropout-105         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-106             [-1, 577, 768]               0\n",
      "          Linear-107             [-1, 577, 768]         590,592\n",
      "         Dropout-108             [-1, 577, 768]               0\n",
      "       LayerNorm-109             [-1, 577, 768]           1,536\n",
      "          Linear-110            [-1, 577, 3072]       2,362,368\n",
      "          Linear-111             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-112             [-1, 577, 768]               0\n",
      "         Dropout-113             [-1, 577, 768]               0\n",
      "           Block-114             [-1, 577, 768]               0\n",
      "       LayerNorm-115             [-1, 577, 768]           1,536\n",
      "          Linear-116             [-1, 577, 768]         590,592\n",
      "          Linear-117             [-1, 577, 768]         590,592\n",
      "          Linear-118             [-1, 577, 768]         590,592\n",
      "         Dropout-119         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-120             [-1, 577, 768]               0\n",
      "          Linear-121             [-1, 577, 768]         590,592\n",
      "         Dropout-122             [-1, 577, 768]               0\n",
      "       LayerNorm-123             [-1, 577, 768]           1,536\n",
      "          Linear-124            [-1, 577, 3072]       2,362,368\n",
      "          Linear-125             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-126             [-1, 577, 768]               0\n",
      "         Dropout-127             [-1, 577, 768]               0\n",
      "           Block-128             [-1, 577, 768]               0\n",
      "       LayerNorm-129             [-1, 577, 768]           1,536\n",
      "          Linear-130             [-1, 577, 768]         590,592\n",
      "          Linear-131             [-1, 577, 768]         590,592\n",
      "          Linear-132             [-1, 577, 768]         590,592\n",
      "         Dropout-133         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-134             [-1, 577, 768]               0\n",
      "          Linear-135             [-1, 577, 768]         590,592\n",
      "         Dropout-136             [-1, 577, 768]               0\n",
      "       LayerNorm-137             [-1, 577, 768]           1,536\n",
      "          Linear-138            [-1, 577, 3072]       2,362,368\n",
      "          Linear-139             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-140             [-1, 577, 768]               0\n",
      "         Dropout-141             [-1, 577, 768]               0\n",
      "           Block-142             [-1, 577, 768]               0\n",
      "       LayerNorm-143             [-1, 577, 768]           1,536\n",
      "          Linear-144             [-1, 577, 768]         590,592\n",
      "          Linear-145             [-1, 577, 768]         590,592\n",
      "          Linear-146             [-1, 577, 768]         590,592\n",
      "         Dropout-147         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-148             [-1, 577, 768]               0\n",
      "          Linear-149             [-1, 577, 768]         590,592\n",
      "         Dropout-150             [-1, 577, 768]               0\n",
      "       LayerNorm-151             [-1, 577, 768]           1,536\n",
      "          Linear-152            [-1, 577, 3072]       2,362,368\n",
      "          Linear-153             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-154             [-1, 577, 768]               0\n",
      "         Dropout-155             [-1, 577, 768]               0\n",
      "           Block-156             [-1, 577, 768]               0\n",
      "       LayerNorm-157             [-1, 577, 768]           1,536\n",
      "          Linear-158             [-1, 577, 768]         590,592\n",
      "          Linear-159             [-1, 577, 768]         590,592\n",
      "          Linear-160             [-1, 577, 768]         590,592\n",
      "         Dropout-161         [-1, 12, 577, 577]               0\n",
      "MultiHeadedSelfAttention-162             [-1, 577, 768]               0\n",
      "          Linear-163             [-1, 577, 768]         590,592\n",
      "         Dropout-164             [-1, 577, 768]               0\n",
      "       LayerNorm-165             [-1, 577, 768]           1,536\n",
      "          Linear-166            [-1, 577, 3072]       2,362,368\n",
      "          Linear-167             [-1, 577, 768]       2,360,064\n",
      "PositionWiseFeedForward-168             [-1, 577, 768]               0\n",
      "         Dropout-169             [-1, 577, 768]               0\n",
      "           Block-170             [-1, 577, 768]               0\n",
      "     Transformer-171             [-1, 577, 768]               0\n",
      "       LayerNorm-172             [-1, 577, 768]           1,536\n",
      "          Linear-173                   [-1, 18]          13,842\n",
      "             ViT-174                   [-1, 18]               0\n",
      "================================================================\n",
      "Total params: 85,660,434\n",
      "Trainable params: 13,842\n",
      "Non-trainable params: 85,646,592\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 1028.41\n",
      "Params size (MB): 326.77\n",
      "Estimated Total Size (MB): 1356.87\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, input_size=(3,384, 384), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    Pad((114,0,114,114)),\n",
    "    CenterCrop((360, 360)),\n",
    "    A.HorizontalFlip(p=.5),\n",
    "\n",
    "    A.augmentations.geometric.transforms.ShiftScaleRotate(rotate_limit= 10, p = 0.2),\n",
    "    A.augmentations.transforms.GaussNoise(var_limit=(10,20), mean=0, per_channel= True, p=0.4),\n",
    "    A.augmentations.geometric.transforms.ShiftScaleRotate(),\n",
    "    A.augmentations.transforms.CLAHE(),\n",
    "    A.augmentations.transforms.RandomBrightnessContrast(),\n",
    "    A.augmentations.transforms.RandomGamma(),\n",
    "    A.augmentations.transforms.HueSaturationValue(),\n",
    "    A.augmentations.transforms.RGBShift(),\n",
    "\n",
    "    # Resize(resize, Image.BILINEAR),\n",
    "    # ToTensor(),\n",
    "    # Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "train_dir = '/opt/ml/input/data/train'\n",
    "\n",
    "train_info = pd.read_csv(os.path.join(train_dir, 'train.csv'))\n",
    "image_dir = os.path.join(train_dir, 'images')\n",
    "\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in train_info.path]\n",
    "\n",
    "example_image = Image.open(os.path.join(image_paths[500], 'mask5.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "image must be numpy array type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb Cell 20'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000019vscode-remote?line=0'>1</a>\u001b[0m transform(image \u001b[39m=\u001b[39;49m example_image)[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py:195\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py?line=192'>193</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to pass data to augmentations as named arguments, for example: aug(image=image)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py?line=193'>194</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_check_args:\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py?line=194'>195</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_args(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py?line=195'>196</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(force_apply, (\u001b[39mbool\u001b[39m, \u001b[39mint\u001b[39m)), \u001b[39m\"\u001b[39m\u001b[39mforce_apply must have bool or int type\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py?line=196'>197</a>\u001b[0m need_to_run \u001b[39m=\u001b[39m force_apply \u001b[39mor\u001b[39;00m random\u001b[39m.\u001b[39mrandom() \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py:271\u001b[0m, in \u001b[0;36mCompose._check_args\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py?line=268'>269</a>\u001b[0m \u001b[39mif\u001b[39;00m internal_data_name \u001b[39min\u001b[39;00m checked_single:\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py?line=269'>270</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py?line=270'>271</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m must be numpy array type\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(data_name))\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py?line=271'>272</a>\u001b[0m \u001b[39mif\u001b[39;00m internal_data_name \u001b[39min\u001b[39;00m checked_multi:\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/albumentations/core/composition.py?line=272'>273</a>\u001b[0m     \u001b[39mif\u001b[39;00m data:\n",
      "\u001b[0;31mTypeError\u001b[0m: image must be numpy array type"
     ]
    }
   ],
   "source": [
    "transform(image = example_image)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(*(2,2))\n",
    "])\n",
    "from albumentations.pytorch import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoodAugmentation:\n",
    "    \"\"\"\n",
    "    사람들이 많이 사용하는 Augmentation의 집합\n",
    "    \"\"\"\n",
    "    def __init__(self, resize, mean, std, **args):\n",
    "\n",
    "        self.transform = A.Compose([\n",
    "            # Pad((114,0,114,114)),\n",
    "            # CenterCrop((360, 360)),\n",
    "            A.Resize(*resize), \n",
    "            A.HorizontalFlip(p=.5),\n",
    "            A.augmentations.geometric.transforms.ShiftScaleRotate(rotate_limit= 10, p = 0.2),\n",
    "            A.augmentations.transforms.GaussNoise(var_limit=(10,20), mean=0, per_channel= True, p=0.4),\n",
    "            A.augmentations.geometric.transforms.ShiftScaleRotate(),\n",
    "            A.augmentations.transforms.CLAHE(),\n",
    "            A.augmentations.transforms.RandomBrightnessContrast(),\n",
    "            A.augmentations.transforms.RandomGamma(),\n",
    "            A.augmentations.transforms.HueSaturationValue(),\n",
    "            A.augmentations.transforms.RGBShift(),\n",
    "            A.Normalize(mean=mean, std=std),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb Cell 24'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000023vscode-remote?line=0'>1</a>\u001b[0m transform \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000023vscode-remote?line=1'>2</a>\u001b[0m     A\u001b[39m.\u001b[39mRandomBrightnessContrast(brightness_limit\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, contrast_limit\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, p\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000023vscode-remote?line=2'>3</a>\u001b[0m ])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000023vscode-remote?line=3'>4</a>\u001b[0m transformed_image_1 \u001b[39m=\u001b[39m transform(image\u001b[39m=\u001b[39mimage)[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000023vscode-remote?line=4'>5</a>\u001b[0m transformed_image_2 \u001b[39m=\u001b[39m transform(image\u001b[39m=\u001b[39mimage)[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "transform = A.Compose([\n",
    "    A.RandomBrightnessContrast(brightness_limit=1, contrast_limit=1, p=1.0),\n",
    "])\n",
    "transformed_image_1 = transform(image=image)['image']\n",
    "transformed_image_2 = transform(image=image)['image']\n",
    "transformed_image_3 = transform(image=image)['image']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Dropout(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        self.resnet18.fc = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n",
    "        # https://discuss.pytorch.org/t/inject-dropout-into-resnet-or-any-other-network/66322/3\n",
    "        self.resnet18.fc.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.5, training=m.training))        \n",
    "\n",
    "        # initialize w & b\n",
    "        torch.nn.init.xavier_uniform_(self.resnet18.fc.weight)\n",
    "        stdv = 1 / math.sqrt(self.resnet18.fc.in_features)\n",
    "        self.resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet18Dropout(\n",
       "  (resnet18): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18Dropout(18)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 150, 150]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 150, 150]             128\n",
      "              ReLU-3         [-1, 64, 150, 150]               0\n",
      "         MaxPool2d-4           [-1, 64, 75, 75]               0\n",
      "            Conv2d-5           [-1, 64, 75, 75]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 75, 75]             128\n",
      "              ReLU-7           [-1, 64, 75, 75]               0\n",
      "            Conv2d-8           [-1, 64, 75, 75]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 75, 75]             128\n",
      "             ReLU-10           [-1, 64, 75, 75]               0\n",
      "       BasicBlock-11           [-1, 64, 75, 75]               0\n",
      "           Conv2d-12           [-1, 64, 75, 75]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 75, 75]             128\n",
      "             ReLU-14           [-1, 64, 75, 75]               0\n",
      "           Conv2d-15           [-1, 64, 75, 75]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 75, 75]             128\n",
      "             ReLU-17           [-1, 64, 75, 75]               0\n",
      "       BasicBlock-18           [-1, 64, 75, 75]               0\n",
      "           Conv2d-19          [-1, 128, 38, 38]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 38, 38]             256\n",
      "             ReLU-21          [-1, 128, 38, 38]               0\n",
      "           Conv2d-22          [-1, 128, 38, 38]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 38, 38]             256\n",
      "           Conv2d-24          [-1, 128, 38, 38]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 38, 38]             256\n",
      "             ReLU-26          [-1, 128, 38, 38]               0\n",
      "       BasicBlock-27          [-1, 128, 38, 38]               0\n",
      "           Conv2d-28          [-1, 128, 38, 38]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 38, 38]             256\n",
      "             ReLU-30          [-1, 128, 38, 38]               0\n",
      "           Conv2d-31          [-1, 128, 38, 38]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 38, 38]             256\n",
      "             ReLU-33          [-1, 128, 38, 38]               0\n",
      "       BasicBlock-34          [-1, 128, 38, 38]               0\n",
      "           Conv2d-35          [-1, 256, 19, 19]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 19, 19]             512\n",
      "             ReLU-37          [-1, 256, 19, 19]               0\n",
      "           Conv2d-38          [-1, 256, 19, 19]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 19, 19]             512\n",
      "           Conv2d-40          [-1, 256, 19, 19]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 19, 19]             512\n",
      "             ReLU-42          [-1, 256, 19, 19]               0\n",
      "       BasicBlock-43          [-1, 256, 19, 19]               0\n",
      "           Conv2d-44          [-1, 256, 19, 19]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 19, 19]             512\n",
      "             ReLU-46          [-1, 256, 19, 19]               0\n",
      "           Conv2d-47          [-1, 256, 19, 19]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 19, 19]             512\n",
      "             ReLU-49          [-1, 256, 19, 19]               0\n",
      "       BasicBlock-50          [-1, 256, 19, 19]               0\n",
      "           Conv2d-51          [-1, 512, 10, 10]       1,179,648\n",
      "      BatchNorm2d-52          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-53          [-1, 512, 10, 10]               0\n",
      "           Conv2d-54          [-1, 512, 10, 10]       2,359,296\n",
      "      BatchNorm2d-55          [-1, 512, 10, 10]           1,024\n",
      "           Conv2d-56          [-1, 512, 10, 10]         131,072\n",
      "      BatchNorm2d-57          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-58          [-1, 512, 10, 10]               0\n",
      "       BasicBlock-59          [-1, 512, 10, 10]               0\n",
      "           Conv2d-60          [-1, 512, 10, 10]       2,359,296\n",
      "      BatchNorm2d-61          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-62          [-1, 512, 10, 10]               0\n",
      "           Conv2d-63          [-1, 512, 10, 10]       2,359,296\n",
      "      BatchNorm2d-64          [-1, 512, 10, 10]           1,024\n",
      "             ReLU-65          [-1, 512, 10, 10]               0\n",
      "       BasicBlock-66          [-1, 512, 10, 10]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 18]           9,234\n",
      "           ResNet-69                   [-1, 18]               0\n",
      "================================================================\n",
      "Total params: 11,185,746\n",
      "Trainable params: 11,185,746\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.02\n",
      "Forward/backward pass size (MB): 114.26\n",
      "Params size (MB): 42.67\n",
      "Estimated Total Size (MB): 157.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(model, (3,299,299), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fae346aa2b0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaseModel(18)\n",
    "model.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.5, training=m.training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 56, 56]             128\n",
      "              ReLU-3           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-4           [-1, 64, 28, 28]               0\n",
      "            Conv2d-5           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "              ReLU-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "             ReLU-10           [-1, 64, 28, 28]               0\n",
      "       BasicBlock-11           [-1, 64, 28, 28]               0\n",
      "           Conv2d-12           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 28, 28]             128\n",
      "             ReLU-14           [-1, 64, 28, 28]               0\n",
      "           Conv2d-15           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 28, 28]             128\n",
      "             ReLU-17           [-1, 64, 28, 28]               0\n",
      "       BasicBlock-18           [-1, 64, 28, 28]               0\n",
      "           Conv2d-19          [-1, 128, 14, 14]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 14, 14]             256\n",
      "             ReLU-21          [-1, 128, 14, 14]               0\n",
      "           Conv2d-22          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 14, 14]             256\n",
      "           Conv2d-24          [-1, 128, 14, 14]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 14, 14]             256\n",
      "             ReLU-26          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-27          [-1, 128, 14, 14]               0\n",
      "           Conv2d-28          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 14, 14]             256\n",
      "             ReLU-30          [-1, 128, 14, 14]               0\n",
      "           Conv2d-31          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 14, 14]             256\n",
      "             ReLU-33          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-34          [-1, 128, 14, 14]               0\n",
      "           Conv2d-35            [-1, 256, 7, 7]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 7, 7]             512\n",
      "             ReLU-37            [-1, 256, 7, 7]               0\n",
      "           Conv2d-38            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 7, 7]             512\n",
      "           Conv2d-40            [-1, 256, 7, 7]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 7, 7]             512\n",
      "             ReLU-42            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-43            [-1, 256, 7, 7]               0\n",
      "           Conv2d-44            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 7, 7]             512\n",
      "             ReLU-46            [-1, 256, 7, 7]               0\n",
      "           Conv2d-47            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 7, 7]             512\n",
      "             ReLU-49            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-50            [-1, 256, 7, 7]               0\n",
      "           Conv2d-51            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-53            [-1, 512, 4, 4]               0\n",
      "           Conv2d-54            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-56            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-58            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-59            [-1, 512, 4, 4]               0\n",
      "           Conv2d-60            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-62            [-1, 512, 4, 4]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-65            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-66            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "          Dropout-68                  [-1, 512]               0\n",
      "================================================================\n",
      "Total params: 11,176,512\n",
      "Trainable params: 11,176,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 15.94\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 58.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "num_classes = 18\n",
    "resnet18.fc = nn.Dropout(0.5)\n",
    "nn.Linear(in_features=512, out_features=num_classes, bias=True)\n",
    "\n",
    "import torchsummary\n",
    "torchsummary.summary(resnet18, (3,111,111), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "num_classes = 18\n",
    "resnet18.fc = nn.ModuleList(\n",
    "    [nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=512, out_features=num_classes, bias=True)]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.one = nn.Linear(in_features=2, out_features=3, bias=False)\n",
    "        self.one.weight.requires_grad = False\n",
    "        self.one.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.5, training=m.training))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x  = self.one(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.2037, -1.7893]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.ones(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (one): Linear(in_features=2, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fae34702940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resnet18.fc.register_forward_hook(lambda m, inp: F.dropout(input=inp, p=0.5, training=m.training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18.avgpool.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb Cell 38'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000037vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMyModel\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000037vscode-remote?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, classes):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000037vscode-remote?line=2'>3</a>\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super().__init__()\n",
    "        self.out_dim = classes\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(0.5) for _ in range(5)\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.linear = nn.Linear(in_features=2, out_features=3, bias=False)\n",
    "        self.one.weight.requires_grad = False\n",
    "        self.one.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.5, training=m.training))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x  = self.one(x)\n",
    "        return x\n",
    "\n",
    "import torch.nn as nn\n",
    "class ResNet18MSD(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(0.5) for _ in range(5)\n",
    "        ])\n",
    "        self.linear = nn.Linear(in_features=2, out_features=num_classes, bias=False)\n",
    "\n",
    "        # initialize w & b\n",
    "        torch.nn.init.xavier_uniform_(self.resnet18.fc.weight)\n",
    "        stdv = 1 / math.sqrt(self.resnet18.fc.in_features)\n",
    "        self.resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                h = self.linear(dropout(x))\n",
    "            else:\n",
    "                h += self.linear(dropout(x))\n",
    "        output = h / len(self.dropouts)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class ResNet18MSD(nn.Module):\n",
    "    \"\"\"_summary_\n",
    "    Name: Multi-sample Dropout ResNet18-pretrained\n",
    "\n",
    "    Args:\n",
    "        nn (_type_): _description_\n",
    "    \n",
    "    self.dropout_p = 0.5 (default):  \n",
    "        the percentile of each dropout layers\n",
    "        \n",
    "    self.dropout_n = 5 (default):  \n",
    "        the number of dropout layers\n",
    "\n",
    "\n",
    "    ref: https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/100961\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.dropout_p = 0.5\n",
    "        self.dropout_n = 5\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(self.dropout_p) for _ in range(self.dropout_n)\n",
    "        ])\n",
    "        in_features = self.resnet18.fc.out_features\n",
    "        self.linear = nn.Linear(in_features=in_features, out_features=num_classes, bias=True)\n",
    "\n",
    "        # initialize w & b\n",
    "        torch.nn.init.xavier_uniform_(self.resnet18.fc.weight)\n",
    "        stdv = 1 / math.sqrt(self.resnet18.fc.in_features)\n",
    "        self.resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                h = self.linear(dropout(x))\n",
    "            else:\n",
    "                h += self.linear(dropout(x))\n",
    "        output = h / len(self.dropouts)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_p = 0.5\n",
    "dropout_n = 5\n",
    "num_classes = 18\n",
    "\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "dropouts = nn.ModuleList([\n",
    "    nn.Dropout(dropout_p) for _ in range(dropout_n)\n",
    "])\n",
    "in_features = resnet18.fc.out_features\n",
    "linear = nn.Linear(in_features=in_features, out_features=num_classes, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros(1, 3,256, 256)\n",
    "x = resnet18(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n",
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(dropouts[0](x).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5756, -0.9549, -1.4656, -0.3327,  0.9887, -1.3598, -0.3762,  0.4157,\n",
       "         0.5999,  0.8185,  1.9030,  0.2581,  1.1759, -0.3088,  1.5117, -0.0159,\n",
       "         0.5780, -0.0336], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(dropouts[0](x).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1287,  0.1866, -1.1070,  1.0414, -0.2110, -0.3907, -0.4316,  0.2452,\n",
       "          0.7150,  1.1592,  1.0270, -0.8453,  0.4880, -0.4587,  1.3571,  0.1753,\n",
       "          0.5610,  0.0103]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(dropouts[0](x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 1, 1000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropouts[0](x).size() + dropouts[1](x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "model = ResNet18MSD(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 56, 56]             128\n",
      "              ReLU-3           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-4           [-1, 64, 28, 28]               0\n",
      "            Conv2d-5           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "              ReLU-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "             ReLU-10           [-1, 64, 28, 28]               0\n",
      "       BasicBlock-11           [-1, 64, 28, 28]               0\n",
      "           Conv2d-12           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 28, 28]             128\n",
      "             ReLU-14           [-1, 64, 28, 28]               0\n",
      "           Conv2d-15           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 28, 28]             128\n",
      "             ReLU-17           [-1, 64, 28, 28]               0\n",
      "       BasicBlock-18           [-1, 64, 28, 28]               0\n",
      "           Conv2d-19          [-1, 128, 14, 14]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 14, 14]             256\n",
      "             ReLU-21          [-1, 128, 14, 14]               0\n",
      "           Conv2d-22          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 14, 14]             256\n",
      "           Conv2d-24          [-1, 128, 14, 14]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 14, 14]             256\n",
      "             ReLU-26          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-27          [-1, 128, 14, 14]               0\n",
      "           Conv2d-28          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 14, 14]             256\n",
      "             ReLU-30          [-1, 128, 14, 14]               0\n",
      "           Conv2d-31          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 14, 14]             256\n",
      "             ReLU-33          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-34          [-1, 128, 14, 14]               0\n",
      "           Conv2d-35            [-1, 256, 7, 7]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 7, 7]             512\n",
      "             ReLU-37            [-1, 256, 7, 7]               0\n",
      "           Conv2d-38            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 7, 7]             512\n",
      "           Conv2d-40            [-1, 256, 7, 7]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 7, 7]             512\n",
      "             ReLU-42            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-43            [-1, 256, 7, 7]               0\n",
      "           Conv2d-44            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 7, 7]             512\n",
      "             ReLU-46            [-1, 256, 7, 7]               0\n",
      "           Conv2d-47            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 7, 7]             512\n",
      "             ReLU-49            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-50            [-1, 256, 7, 7]               0\n",
      "           Conv2d-51            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-53            [-1, 512, 4, 4]               0\n",
      "           Conv2d-54            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-56            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-58            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-59            [-1, 512, 4, 4]               0\n",
      "           Conv2d-60            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-62            [-1, 512, 4, 4]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-65            [-1, 512, 4, 4]               0\n",
      "       BasicBlock-66            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "           ResNet-69                 [-1, 1000]               0\n",
      "          Dropout-70                 [-1, 1000]               0\n",
      "           Linear-71                   [-1, 18]          18,018\n",
      "          Dropout-72                 [-1, 1000]               0\n",
      "           Linear-73                   [-1, 18]          18,018\n",
      "          Dropout-74                 [-1, 1000]               0\n",
      "           Linear-75                   [-1, 18]          18,018\n",
      "          Dropout-76                 [-1, 1000]               0\n",
      "           Linear-77                   [-1, 18]          18,018\n",
      "          Dropout-78                 [-1, 1000]               0\n",
      "           Linear-79                   [-1, 18]          18,018\n",
      "================================================================\n",
      "Total params: 11,779,602\n",
      "Trainable params: 11,779,602\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 15.99\n",
      "Params size (MB): 44.94\n",
      "Estimated Total Size (MB): 61.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(model, (3, 111,111), device='cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=True)\n",
    "        self.resnet18.fc = nn.Linear(in_features=512, out_features=num_classes, bias=True)\n",
    "        # self.Linear_1 = nn.Linear(in_features=1000, out_features = num_classes)\n",
    "\n",
    "        # initialize w & b\n",
    "        torch.nn.init.xavier_uniform_(self.resnet18.fc.weight)\n",
    "        stdv = 1 / math.sqrt(self.resnet18.fc.in_features)\n",
    "        self.resnet18.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetB4FreezeTop6(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.efficientnet = models.efficientnet_b4(pretrained=True)\n",
    "\n",
    "        in_features = self.efficientnet.classifier[1].in_features\n",
    "        self.efficientnet.classifier[1] = nn.Linear(in_features=in_features, out_features=num_classes)\n",
    "        # self.linear = nn.Linear(in_features = self.efficientnet._fc.out_features, out_features = num_classes)\n",
    "\n",
    "        # initialize w & b\n",
    "        torch.nn.init.xavier_uniform_(self.efficientnet.classifier[1].weight)\n",
    "        stdv = 1 / math.sqrt(self.efficientnet.classifier[1].in_features)\n",
    "        self.efficientnet.classifier[1].bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "        # Freeze Top 6 layers\n",
    "        for i, child in enumerate(self.efficientnet.children()):\n",
    "            if i == 6 : break # break point; Top 6 layers\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.efficientnet(x)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/.venv/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 64, 5, 5]           9,408\n",
      "       BatchNorm2d-2             [-1, 64, 5, 5]             128\n",
      "              ReLU-3             [-1, 64, 5, 5]               0\n",
      "         MaxPool2d-4             [-1, 64, 3, 3]               0\n",
      "            Conv2d-5             [-1, 64, 3, 3]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 3, 3]             128\n",
      "              ReLU-7             [-1, 64, 3, 3]               0\n",
      "            Conv2d-8             [-1, 64, 3, 3]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 3, 3]             128\n",
      "             ReLU-10             [-1, 64, 3, 3]               0\n",
      "       BasicBlock-11             [-1, 64, 3, 3]               0\n",
      "           Conv2d-12             [-1, 64, 3, 3]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 3, 3]             128\n",
      "             ReLU-14             [-1, 64, 3, 3]               0\n",
      "           Conv2d-15             [-1, 64, 3, 3]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 3, 3]             128\n",
      "             ReLU-17             [-1, 64, 3, 3]               0\n",
      "       BasicBlock-18             [-1, 64, 3, 3]               0\n",
      "           Conv2d-19            [-1, 128, 2, 2]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 2, 2]             256\n",
      "             ReLU-21            [-1, 128, 2, 2]               0\n",
      "           Conv2d-22            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 2, 2]             256\n",
      "           Conv2d-24            [-1, 128, 2, 2]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 2, 2]             256\n",
      "             ReLU-26            [-1, 128, 2, 2]               0\n",
      "       BasicBlock-27            [-1, 128, 2, 2]               0\n",
      "           Conv2d-28            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 2, 2]             256\n",
      "             ReLU-30            [-1, 128, 2, 2]               0\n",
      "           Conv2d-31            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 2, 2]             256\n",
      "             ReLU-33            [-1, 128, 2, 2]               0\n",
      "       BasicBlock-34            [-1, 128, 2, 2]               0\n",
      "           Conv2d-35            [-1, 256, 1, 1]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 1, 1]             512\n",
      "             ReLU-37            [-1, 256, 1, 1]               0\n",
      "           Conv2d-38            [-1, 256, 1, 1]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 1, 1]             512\n",
      "           Conv2d-40            [-1, 256, 1, 1]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 1, 1]             512\n",
      "             ReLU-42            [-1, 256, 1, 1]               0\n",
      "       BasicBlock-43            [-1, 256, 1, 1]               0\n",
      "           Conv2d-44            [-1, 256, 1, 1]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 1, 1]             512\n",
      "             ReLU-46            [-1, 256, 1, 1]               0\n",
      "           Conv2d-47            [-1, 256, 1, 1]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 1, 1]             512\n",
      "             ReLU-49            [-1, 256, 1, 1]               0\n",
      "       BasicBlock-50            [-1, 256, 1, 1]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 18]           9,234\n",
      "           ResNet-69                   [-1, 18]               0\n",
      "================================================================\n",
      "Total params: 11,185,746\n",
      "Trainable params: 11,185,746\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.26\n",
      "Params size (MB): 42.67\n",
      "Estimated Total Size (MB): 42.93\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb Cell 51'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000078vscode-remote?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m ResNet18(\u001b[39m18\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000078vscode-remote?line=1'>2</a>\u001b[0m torchsummary\u001b[39m.\u001b[39msummary(model, (\u001b[39m3\u001b[39m, \u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m), device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000078vscode-remote?line=2'>3</a>\u001b[0m model(torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m10\u001b[39;49m,\u001b[39m10\u001b[39;49m))\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb Cell 5'\u001b[0m in \u001b[0;36mResNet18.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000004vscode-remote?line=47'>48</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000004vscode-remote?line=48'>49</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresnet18(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000004vscode-remote?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py:249\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=247'>248</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=248'>249</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py:239\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=236'>237</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(x)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=237'>238</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=238'>239</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer3(x)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=239'>240</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer4(x)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=241'>242</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=136'>137</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=137'>138</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py:71\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=67'>68</a>\u001b[0m identity \u001b[39m=\u001b[39m x\n\u001b[1;32m     <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=69'>70</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m---> <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=70'>71</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn1(out)\n\u001b[1;32m     <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=71'>72</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m     <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=73'>74</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:167\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=159'>160</a>\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=161'>162</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=162'>163</a>\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=163'>164</a>\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=164'>165</a>\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=165'>166</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=166'>167</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=167'>168</a>\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=168'>169</a>\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=169'>170</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=170'>171</a>\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=171'>172</a>\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=172'>173</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=173'>174</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=174'>175</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=175'>176</a>\u001b[0m     bn_training,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=176'>177</a>\u001b[0m     exponential_average_factor,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=177'>178</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=178'>179</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2279\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2265'>2266</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2266'>2267</a>\u001b[0m         batch_norm,\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2267'>2268</a>\u001b[0m         (\u001b[39minput\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2275'>2276</a>\u001b[0m         eps\u001b[39m=\u001b[39meps,\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2276'>2277</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2277'>2278</a>\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2278'>2279</a>\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msize())\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2280'>2281</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mbatch_norm(\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2281'>2282</a>\u001b[0m     \u001b[39minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mcudnn\u001b[39m.\u001b[39menabled\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2282'>2283</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2247\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2244'>2245</a>\u001b[0m     size_prods \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m size[i \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2245'>2246</a>\u001b[0m \u001b[39mif\u001b[39;00m size_prods \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2246'>2247</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(size))\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])"
     ]
    }
   ],
   "source": [
    "model = ResNet18(18)\n",
    "torchsummary.summary(model, (3, 10,10), device='cpu')\n",
    "model(torch.zeros(1,3,10,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): ConvNormActivation(\n",
       "      (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
       "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.00625, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.018750000000000003, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.043750000000000004, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
       "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05625, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(336, 336, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=336, bias=False)\n",
       "            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06875, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08125, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09375, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10625000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11875000000000001, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14375000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15625, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16875, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "      (7): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18125000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n",
       "            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n",
       "            (1): BatchNorm2d(2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19375, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): ConvNormActivation(\n",
       "      (0): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.4, inplace=True)\n",
       "    (1): Linear(in_features=1792, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet = models.efficientnet_b4(pretrained=True)\n",
    "efficientnet.classifier[1] = nn.Linear(in_features=1792, out_features=18, bias=True)\n",
    "efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "class EfficientNetB4MSD(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.dropout_p = 0.5\n",
    "        self.dropout_n = 5\n",
    "        self.efficientnet = torchvision.models.efficientnet_b4(pretrained=True)\n",
    "\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(self.dropout_p) for _ in range(self.dropout_n)\n",
    "        ])\n",
    "\n",
    "        in_features = self.efficientnet.fc.out_features\n",
    "        self.linear = nn.Linear(in_features=in_features, out_features=num_classes)\n",
    "        # self.linear = nn.Linear(in_features = self.efficientnet._fc.out_features, out_features = num_classes)\n",
    "\n",
    "        # initialize w & b\n",
    "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
    "        stdv = 1 / math.sqrt(self.linear.in_features)\n",
    "        self.linear.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet18(x)\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                h = self.linear(dropout(x))\n",
    "            else:\n",
    "                h += self.linear(dropout(x))\n",
    "        output = h / len(self.dropouts)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-cf984f9c.pth\" to /opt/ml/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-cf984f9c.pth\n",
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): ConvNormActivation(\n",
       "      (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): ConvNormActivation(\n",
       "            (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): ConvNormActivation(\n",
       "            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): ConvNormActivation(\n",
       "            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): ConvNormActivation(\n",
       "      (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=True)\n",
       "    (1): Linear(in_features=1536, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b3(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EfficientNet' object has no attribute 'fc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb Cell 51'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000051vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000051vscode-remote?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m EfficientNetB4MSD(\u001b[39m18\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000051vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000051vscode-remote?line=4'>5</a>\u001b[0m torchsummary\u001b[39m.\u001b[39msummary(model, (\u001b[39m3\u001b[39m, \u001b[39m111\u001b[39m,\u001b[39m111\u001b[39m), device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb Cell 49'\u001b[0m in \u001b[0;36mEfficientNetB4MSD.__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000042vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mefficientnet \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mefficientnet_b4(pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000042vscode-remote?line=8'>9</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropouts \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mModuleList([\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000042vscode-remote?line=9'>10</a>\u001b[0m     nn\u001b[39m.\u001b[39mDropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_p) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout_n)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000042vscode-remote?line=10'>11</a>\u001b[0m ])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000042vscode-remote?line=12'>13</a>\u001b[0m in_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mefficientnet\u001b[39m.\u001b[39;49mfc\u001b[39m.\u001b[39mout_features\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000042vscode-remote?line=13'>14</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(in_features\u001b[39m=\u001b[39min_features, out_features\u001b[39m=\u001b[39mnum_classes)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000042vscode-remote?line=14'>15</a>\u001b[0m \u001b[39m# self.linear = nn.Linear(in_features = self.efficientnet._fc.out_features, out_features = num_classes)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000042vscode-remote?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000042vscode-remote?line=16'>17</a>\u001b[0m \u001b[39m# initialize w & b\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1177\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1174'>1175</a>\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1175'>1176</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1176'>1177</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1177'>1178</a>\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EfficientNet' object has no attribute 'fc'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "model = EfficientNetB4MSD(18)\n",
    "\n",
    "import torchsummary\n",
    "torchsummary.summary(model, (3, 111,111), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.2'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 03.01\n",
    "class ResNet34FreezeTop6(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet34(pretrained=True)\n",
    "        self.model.fc = nn.Linear(in_features=self.model.fc.in_features, out_features=num_classes, bias=True)\n",
    "\n",
    "        # initialize w & b\n",
    "        torch.nn.init.xavier_uniform_(self.model.fc.weight)\n",
    "        stdv = 1 / math.sqrt(self.model.fc.in_features)\n",
    "        self.model.fc.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "        # freeze top 6 layers\n",
    "        for i, child in enumerate(self.model.children()):\n",
    "            if i == 6 : break # break point\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet34FreezeTop6(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet34FreezeTop6(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=18, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 56, 56]             128\n",
      "              ReLU-3           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-4           [-1, 64, 28, 28]               0\n",
      "            Conv2d-5           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "              ReLU-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "             ReLU-10           [-1, 64, 28, 28]               0\n",
      "       BasicBlock-11           [-1, 64, 28, 28]               0\n",
      "           Conv2d-12           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 28, 28]             128\n",
      "             ReLU-14           [-1, 64, 28, 28]               0\n",
      "           Conv2d-15           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 28, 28]             128\n",
      "             ReLU-17           [-1, 64, 28, 28]               0\n",
      "       BasicBlock-18           [-1, 64, 28, 28]               0\n",
      "           Conv2d-19           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 28, 28]             128\n",
      "             ReLU-21           [-1, 64, 28, 28]               0\n",
      "           Conv2d-22           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 28, 28]             128\n",
      "             ReLU-24           [-1, 64, 28, 28]               0\n",
      "       BasicBlock-25           [-1, 64, 28, 28]               0\n",
      "           Conv2d-26          [-1, 128, 14, 14]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 14, 14]             256\n",
      "             ReLU-28          [-1, 128, 14, 14]               0\n",
      "           Conv2d-29          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 14, 14]             256\n",
      "           Conv2d-31          [-1, 128, 14, 14]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 14, 14]             256\n",
      "             ReLU-33          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-34          [-1, 128, 14, 14]               0\n",
      "           Conv2d-35          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 14, 14]             256\n",
      "             ReLU-37          [-1, 128, 14, 14]               0\n",
      "           Conv2d-38          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 14, 14]             256\n",
      "             ReLU-40          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-41          [-1, 128, 14, 14]               0\n",
      "           Conv2d-42          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 14, 14]             256\n",
      "             ReLU-44          [-1, 128, 14, 14]               0\n",
      "           Conv2d-45          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 14, 14]             256\n",
      "             ReLU-47          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-48          [-1, 128, 14, 14]               0\n",
      "           Conv2d-49          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 14, 14]             256\n",
      "             ReLU-51          [-1, 128, 14, 14]               0\n",
      "           Conv2d-52          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 14, 14]             256\n",
      "             ReLU-54          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-55          [-1, 128, 14, 14]               0\n",
      "           Conv2d-56            [-1, 256, 7, 7]         294,912\n",
      "      BatchNorm2d-57            [-1, 256, 7, 7]             512\n",
      "             ReLU-58            [-1, 256, 7, 7]               0\n",
      "           Conv2d-59            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 7, 7]             512\n",
      "           Conv2d-61            [-1, 256, 7, 7]          32,768\n",
      "      BatchNorm2d-62            [-1, 256, 7, 7]             512\n",
      "             ReLU-63            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-64            [-1, 256, 7, 7]               0\n",
      "           Conv2d-65            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-66            [-1, 256, 7, 7]             512\n",
      "             ReLU-67            [-1, 256, 7, 7]               0\n",
      "           Conv2d-68            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-69            [-1, 256, 7, 7]             512\n",
      "             ReLU-70            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-71            [-1, 256, 7, 7]               0\n",
      "           Conv2d-72            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 7, 7]             512\n",
      "             ReLU-74            [-1, 256, 7, 7]               0\n",
      "           Conv2d-75            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 7, 7]             512\n",
      "             ReLU-77            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-78            [-1, 256, 7, 7]               0\n",
      "           Conv2d-79            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 7, 7]             512\n",
      "             ReLU-81            [-1, 256, 7, 7]               0\n",
      "           Conv2d-82            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 7, 7]             512\n",
      "             ReLU-84            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-85            [-1, 256, 7, 7]               0\n",
      "           Conv2d-86            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 7, 7]             512\n",
      "             ReLU-88            [-1, 256, 7, 7]               0\n",
      "           Conv2d-89            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-90            [-1, 256, 7, 7]             512\n",
      "             ReLU-91            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-92            [-1, 256, 7, 7]               0\n",
      "           Conv2d-93            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-94            [-1, 256, 7, 7]             512\n",
      "             ReLU-95            [-1, 256, 7, 7]               0\n",
      "           Conv2d-96            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-97            [-1, 256, 7, 7]             512\n",
      "             ReLU-98            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-99            [-1, 256, 7, 7]               0\n",
      "          Conv2d-100            [-1, 512, 4, 4]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-102            [-1, 512, 4, 4]               0\n",
      "          Conv2d-103            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-105            [-1, 512, 4, 4]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-107            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-108            [-1, 512, 4, 4]               0\n",
      "          Conv2d-109            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-111            [-1, 512, 4, 4]               0\n",
      "          Conv2d-112            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-114            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-115            [-1, 512, 4, 4]               0\n",
      "          Conv2d-116            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-118            [-1, 512, 4, 4]               0\n",
      "          Conv2d-119            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-121            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-122            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                   [-1, 18]           9,234\n",
      "          ResNet-125                   [-1, 18]               0\n",
      "================================================================\n",
      "Total params: 21,293,906\n",
      "Trainable params: 19,946,002\n",
      "Non-trainable params: 1,347,904\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 24.41\n",
      "Params size (MB): 81.23\n",
      "Estimated Total Size (MB): 105.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torchsummary.summary(model, (3, 111,111), device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = models.resnet34(pretrained=True)\n",
    "model.eval()\n",
    "model(torch.zeros(1, 3,10,10)).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 56, 56]             128\n",
      "              ReLU-3           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-4           [-1, 64, 28, 28]               0\n",
      "            Conv2d-5           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "              ReLU-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "             ReLU-10           [-1, 64, 28, 28]               0\n",
      "       BasicBlock-11           [-1, 64, 28, 28]               0\n",
      "           Conv2d-12           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 28, 28]             128\n",
      "             ReLU-14           [-1, 64, 28, 28]               0\n",
      "           Conv2d-15           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 28, 28]             128\n",
      "             ReLU-17           [-1, 64, 28, 28]               0\n",
      "       BasicBlock-18           [-1, 64, 28, 28]               0\n",
      "           Conv2d-19           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 28, 28]             128\n",
      "             ReLU-21           [-1, 64, 28, 28]               0\n",
      "           Conv2d-22           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 28, 28]             128\n",
      "             ReLU-24           [-1, 64, 28, 28]               0\n",
      "       BasicBlock-25           [-1, 64, 28, 28]               0\n",
      "           Conv2d-26          [-1, 128, 14, 14]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 14, 14]             256\n",
      "             ReLU-28          [-1, 128, 14, 14]               0\n",
      "           Conv2d-29          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 14, 14]             256\n",
      "           Conv2d-31          [-1, 128, 14, 14]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 14, 14]             256\n",
      "             ReLU-33          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-34          [-1, 128, 14, 14]               0\n",
      "           Conv2d-35          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 14, 14]             256\n",
      "             ReLU-37          [-1, 128, 14, 14]               0\n",
      "           Conv2d-38          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 14, 14]             256\n",
      "             ReLU-40          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-41          [-1, 128, 14, 14]               0\n",
      "           Conv2d-42          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 14, 14]             256\n",
      "             ReLU-44          [-1, 128, 14, 14]               0\n",
      "           Conv2d-45          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 14, 14]             256\n",
      "             ReLU-47          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-48          [-1, 128, 14, 14]               0\n",
      "           Conv2d-49          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 14, 14]             256\n",
      "             ReLU-51          [-1, 128, 14, 14]               0\n",
      "           Conv2d-52          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 14, 14]             256\n",
      "             ReLU-54          [-1, 128, 14, 14]               0\n",
      "       BasicBlock-55          [-1, 128, 14, 14]               0\n",
      "           Conv2d-56            [-1, 256, 7, 7]         294,912\n",
      "      BatchNorm2d-57            [-1, 256, 7, 7]             512\n",
      "             ReLU-58            [-1, 256, 7, 7]               0\n",
      "           Conv2d-59            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 7, 7]             512\n",
      "           Conv2d-61            [-1, 256, 7, 7]          32,768\n",
      "      BatchNorm2d-62            [-1, 256, 7, 7]             512\n",
      "             ReLU-63            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-64            [-1, 256, 7, 7]               0\n",
      "           Conv2d-65            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-66            [-1, 256, 7, 7]             512\n",
      "             ReLU-67            [-1, 256, 7, 7]               0\n",
      "           Conv2d-68            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-69            [-1, 256, 7, 7]             512\n",
      "             ReLU-70            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-71            [-1, 256, 7, 7]               0\n",
      "           Conv2d-72            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 7, 7]             512\n",
      "             ReLU-74            [-1, 256, 7, 7]               0\n",
      "           Conv2d-75            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 7, 7]             512\n",
      "             ReLU-77            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-78            [-1, 256, 7, 7]               0\n",
      "           Conv2d-79            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 7, 7]             512\n",
      "             ReLU-81            [-1, 256, 7, 7]               0\n",
      "           Conv2d-82            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 7, 7]             512\n",
      "             ReLU-84            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-85            [-1, 256, 7, 7]               0\n",
      "           Conv2d-86            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 7, 7]             512\n",
      "             ReLU-88            [-1, 256, 7, 7]               0\n",
      "           Conv2d-89            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-90            [-1, 256, 7, 7]             512\n",
      "             ReLU-91            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-92            [-1, 256, 7, 7]               0\n",
      "           Conv2d-93            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-94            [-1, 256, 7, 7]             512\n",
      "             ReLU-95            [-1, 256, 7, 7]               0\n",
      "           Conv2d-96            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-97            [-1, 256, 7, 7]             512\n",
      "             ReLU-98            [-1, 256, 7, 7]               0\n",
      "       BasicBlock-99            [-1, 256, 7, 7]               0\n",
      "          Conv2d-100            [-1, 512, 4, 4]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-102            [-1, 512, 4, 4]               0\n",
      "          Conv2d-103            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-105            [-1, 512, 4, 4]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-107            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-108            [-1, 512, 4, 4]               0\n",
      "          Conv2d-109            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-111            [-1, 512, 4, 4]               0\n",
      "          Conv2d-112            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-114            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-115            [-1, 512, 4, 4]               0\n",
      "          Conv2d-116            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-118            [-1, 512, 4, 4]               0\n",
      "          Conv2d-119            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-121            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-122            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                   [-1, 18]           9,234\n",
      "          ResNet-125                   [-1, 18]               0\n",
      "================================================================\n",
      "Total params: 21,293,906\n",
      "Trainable params: 19,946,002\n",
      "Non-trainable params: 1,347,904\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 24.41\n",
      "Params size (MB): 81.23\n",
      "Estimated Total Size (MB): 105.78\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb Cell 62'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000059vscode-remote?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m ResNet34FreezeTop6(\u001b[39m18\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000059vscode-remote?line=3'>4</a>\u001b[0m torchsummary\u001b[39m.\u001b[39msummary(model, (\u001b[39m3\u001b[39m, \u001b[39m111\u001b[39m,\u001b[39m111\u001b[39m), device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000059vscode-remote?line=4'>5</a>\u001b[0m model(torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m,\u001b[39m10\u001b[39;49m,\u001b[39m10\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000059vscode-remote?line=5'>6</a>\u001b[0m model\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb Cell 57'\u001b[0m in \u001b[0;36mResNet34FreezeTop6.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000064vscode-remote?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000064vscode-remote?line=21'>22</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000064vscode-remote?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py:249\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=247'>248</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=248'>249</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py:239\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=236'>237</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(x)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=237'>238</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=238'>239</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer3(x)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=239'>240</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer4(x)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=241'>242</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py:71\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=67'>68</a>\u001b[0m identity \u001b[39m=\u001b[39m x\n\u001b[1;32m     <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=69'>70</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m---> <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=70'>71</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn1(out)\n\u001b[1;32m     <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=71'>72</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m     <a href='file:///~/.venv/lib/python3.8/site-packages/torchvision/models/resnet.py?line=73'>74</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(out)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=160'>161</a>\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=162'>163</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=163'>164</a>\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=164'>165</a>\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=165'>166</a>\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=166'>167</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=167'>168</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=168'>169</a>\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=169'>170</a>\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=170'>171</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=171'>172</a>\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=172'>173</a>\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=173'>174</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=174'>175</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=175'>176</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=176'>177</a>\u001b[0m     bn_training,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=177'>178</a>\u001b[0m     exponential_average_factor,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=178'>179</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py?line=179'>180</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2280\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2266'>2267</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2267'>2268</a>\u001b[0m         batch_norm,\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2268'>2269</a>\u001b[0m         (\u001b[39minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2276'>2277</a>\u001b[0m         eps\u001b[39m=\u001b[39meps,\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2277'>2278</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2278'>2279</a>\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2279'>2280</a>\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msize())\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2281'>2282</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mbatch_norm(\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2282'>2283</a>\u001b[0m     \u001b[39minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mcudnn\u001b[39m.\u001b[39menabled\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2283'>2284</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/torch/nn/functional.py:2248\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2245'>2246</a>\u001b[0m     size_prods \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m size[i \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m]\n\u001b[1;32m   <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2246'>2247</a>\u001b[0m \u001b[39mif\u001b[39;00m size_prods \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> <a href='file:///~/.venv/lib/python3.8/site-packages/torch/nn/functional.py?line=2247'>2248</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(size))\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 256, 1, 1])"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "\n",
    "model = ResNet34FreezeTop6(18)\n",
    "torchsummary.summary(model, (3, 111,111), device='cpu')\n",
    "model(torch.zeros(1, 3,10,10))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'ResNet' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb Cell 59'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000060vscode-remote?line=0'>1</a>\u001b[0m model1 \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mresnet34(pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000060vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39;49m(model1))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B49.50.162.191/opt/ml/level1-image-classification-level1-recsys-11/BaseLineCodeV2/_NOT_FOR_USE.ipynb#ch0000060vscode-remote?line=2'>3</a>\u001b[0m torchsummary\u001b[39m.\u001b[39msummary(model1, (\u001b[39m3\u001b[39m, \u001b[39m111\u001b[39m,\u001b[39m111\u001b[39m), device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'ResNet' has no len()"
     ]
    }
   ],
   "source": [
    "model1 = models.resnet34(pretrained=True)\n",
    "print()\n",
    "torchsummary.summary(model1, (3, 111,111), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fc = nn.Linear(512, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model(torch.zeros(1,3,10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(\n",
      "    in_features=512, out_features=Linear(in_features=512, out_features=18, bias=True), bias=True\n",
      "    (out_features): Linear(in_features=512, out_features=18, bias=True)\n",
      "  )\n",
      ")\n",
      "Linear(in_features=512, out_features=18, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8892ab59d46dba3f4efad217c937d392d78b127da621344609ec3a012e116b8b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
