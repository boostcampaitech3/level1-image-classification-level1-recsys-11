{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from deepface import DeepFace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os, shutil, tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def rgb_to_bgr(image):\n",
    "    b, g, r = cv2.split(image)\n",
    "    image = cv2.merge([r, g, b])\n",
    "    return image\n",
    "\n",
    "backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface', 'mediapipe']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = '/opt/ml/input/data_crop_test/train/images'\n",
    "folder_name = os.listdir(folder_dir)\n",
    "folder_name = sorted([x for x in folder_name if '._' not in x]) # '._' 제거\n",
    "\n",
    "file_list = [[folder_name[i]+\"/\"+file for file in os.listdir(os.path.join(folder_dir,folder_name[i])) if '._' not in file and 'ipynb' not in file] for i in range(len(folder_name))]\n",
    "\n",
    "# 모든 이미지명 리스트\n",
    "all_file_list = list(chain(*file_list))\n",
    "\n",
    "# class별 이미지명 리스트\n",
    "incorrect_img = [os.path.join(folder_dir, file) for file in all_file_list if 'incorrect_mask' in file]\n",
    "normal_img = [os.path.join(folder_dir, file) for file in all_file_list if 'normal' in file]\n",
    "mask_img = [os.path.join(folder_dir, file) for file in all_file_list if 'incorrect_mask' not in file and 'normal' not in file]\n",
    "\n",
    "print('모든 이미지 수: ', len(all_file_list))\n",
    "print('incorrect 이미지 수: ', len(incorrect_img))\n",
    "print('normal 이미지 수: ', len(normal_img))\n",
    "print('mask 이미지 수: ', len(mask_img))\n",
    "print('각 list 예시: ',incorrect_img[0], normal_img[0], mask_img[0], sep='\\n')\n",
    "\n",
    "normal_img = [file for file in normal_img if 'crop' not in file.split('/')[-1]]\n",
    "print('normal 이미지 수: ', len(normal_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(7, 5, figsize=(40, 24))\n",
    "backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface', 'mediapipe']\n",
    "\n",
    "for j in range(7):\n",
    "    for i in range(5):\n",
    "        face = DeepFace.detectFace(img_path = normal_img[j], target_size = (224, 224), detector_backend = backends[i])\n",
    "        axes[j][i].imshow(face)\n",
    "        axes[j][i].set_title(backends[i])\n",
    "        axes[j][i].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSD를 사용한 detection \n",
    "age, gender, boxxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = 'ssd'\n",
    "data_normal_df = pd.DataFrame({}, columns=['file', 'age', 'region', 'gender', 'detector'])\n",
    "fail = []\n",
    "\n",
    "for image_file in tqdm.tqdm(normal_img, desc='iteration'):\n",
    "    img_path, img_name = '/'.join(image_file.split('/')[:-1]), image_file.split('/')[-1]\n",
    "    src, dst = img_name.split('.')\n",
    "    \n",
    "    try:\n",
    "        # analyze\n",
    "        obj = DeepFace.analyze(img_path = image_file, actions = ['age', 'gender'], detector_backend=detector)\n",
    "        obj['file'] = image_file\n",
    "        obj['detector'] = detector\n",
    "        \n",
    "        data_normal_df = data_normal_df.append(obj, ignore_index=True)\n",
    "        \n",
    "    except:\n",
    "        fail.append(image_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal_df.head()\n",
    "# data_normal_df.to_csv('detection_normal_ssd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retinaface를 사용한 detection\n",
    "age, gender, boxxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = backends[4] # retinaface\n",
    "data_normal_df_retinaface = pd.DataFrame({}, columns=['file', 'age', 'region', 'gender', 'detector'])\n",
    "fail = []\n",
    "\n",
    "for image_file in tqdm.tqdm(normal_img, desc='iteration'):\n",
    "    img_path, img_name = '/'.join(image_file.split('/')[:-1]), image_file.split('/')[-1]\n",
    "    src, dst = img_name.split('.')\n",
    "    \n",
    "    try:\n",
    "        # analyze\n",
    "        obj = DeepFace.analyze(img_path = image_file, actions = ['age', 'gender'], detector_backend=detector)\n",
    "        obj['file'] = image_file\n",
    "        obj['detector'] = detector\n",
    "        \n",
    "        data_normal_df_retinaface = data_normal_df_retinaface.append(obj, ignore_index=True)\n",
    "        \n",
    "        # crop & save\n",
    "        # face = DeepFace.detectFace(img_path = image_file, target_size = (112, 112), detector_backend = detector)\n",
    "        # cv2.imwrite(os.path.join(img_path, src+\"_crop_{}.\".format(detector)+dst), detected_face)\n",
    "    except:\n",
    "        fail.append(image_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal_df_retinaface.head()\n",
    "data_normal_df_retinaface.to_csv('detection_normal_retinaface.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
