{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import argparse\n",
    "import shutil, os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "def highlightFace(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn=frame.copy()\n",
    "    frameHeight=frameOpencvDnn.shape[0]\n",
    "    frameWidth=frameOpencvDnn.shape[1]\n",
    "    blob=cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections=net.forward()\n",
    "    faceBoxes=[]\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence=detections[0,0,i,2]\n",
    "        if confidence>conf_threshold:\n",
    "            x1=int(detections[0,0,i,3]*frameWidth)\n",
    "            y1=int(detections[0,0,i,4]*frameHeight)\n",
    "            x2=int(detections[0,0,i,5]*frameWidth)\n",
    "            y2=int(detections[0,0,i,6]*frameHeight)\n",
    "            faceBoxes.append([x1,y1,x2,y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1,y1), (x2,y2), (0,255,0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn,faceBoxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faceProto=\"opencv_face_detector.pbtxt\"\n",
    "faceModel=\"opencv_face_detector_uint8.pb\"\n",
    "ageProto=\"age_deploy.prototxt\"\n",
    "ageModel=\"age_net.caffemodel\"\n",
    "genderProto=\"gender_deploy.prototxt\"\n",
    "genderModel=\"gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES=(78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList=['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList=['Male','Female']\n",
    "\n",
    "faceNet=cv2.dnn.readNet(faceModel,faceProto)\n",
    "ageNet=cv2.dnn.readNet(ageModel,ageProto)\n",
    "genderNet=cv2.dnn.readNet(genderModel,genderProto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_range(age):\n",
    "    age_dict = {'age1' : ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)'],\n",
    "                'age2' : ['(38-43)', '(48-53)'],\n",
    "                'age3' : ['(60-100)']}\n",
    "    \n",
    "    if age in age_dict.get('age1'):\n",
    "        age = 'age1'\n",
    "    elif age in age_dict.get('age2'):\n",
    "        age = 'age2'\n",
    "    elif age in age_dict.get('age3'):\n",
    "        age = 'age3'\n",
    "    return age\n",
    "\n",
    "def rgb_to_bgr(image):\n",
    "    image_ = cv2.imread(image)\n",
    "    b, g, r = cv2.split(image_)\n",
    "    image_ = cv2.merge([r, g, b])\n",
    "    return image_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 이미지 수:  18900\n",
      "incorrect class 이미지 수: 2700\n",
      "normal class 이미지 수: 2700\n",
      "mask class 이미지 수: 13500\n"
     ]
    }
   ],
   "source": [
    "folder_dir = '/opt/ml/input/data_re/train/re_images/dir_test'  # 경로를 넣어주세요\n",
    "folder_name = os.listdir(folder_dir)\n",
    "\n",
    "file_list = [[folder_name[i]+\"/\"+file for file in os.listdir(os.path.join(folder_dir,folder_name[i])) if '._' not in file and 'ipynb' not in file] for i in range(len(folder_name))]\n",
    "\n",
    "# 모든 이미지명 리스트\n",
    "all_file_list = list(chain(*file_list))\n",
    "\n",
    "# class별 이미지명 리스트\n",
    "incorrect_img = file_list[0]\n",
    "normal_img = file_list[1]\n",
    "mask_img = file_list[2]\n",
    "\n",
    "print('모든 이미지 수: ', len(all_file_list))\n",
    "print('{} class 이미지 수:'.format(folder_name[0]), len(incorrect_img))\n",
    "print('{} class 이미지 수:'.format(folder_name[1]), len(normal_img))\n",
    "print('{} class 이미지 수:'.format(folder_name[2]), len(mask_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/ml/input/data_re/train/re_images/dir_test/normal/006368_male_Asian_age1_19_normal.jpg'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이미지 파일\n",
    "image = os.path.join(folder_dir, normal_img[332])\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't detect face\n",
      "Can't detect face\n",
      "Can't detect face\n"
     ]
    }
   ],
   "source": [
    "data_all_df = pd.DataFrame({}, columns=['file_name', 'id', 'age', 'age_group','age_group_pred','age_pred', 'gender', 'gender_pred'])\n",
    "error = []\n",
    "\n",
    "for file in normal_img:\n",
    "    image = os.path.join(folder_dir, file)\n",
    "    \n",
    "    frame = cv2.imread(image) # image \n",
    "    gender, age = 'None', 'None'  # gender, age 초기화\n",
    "\n",
    "    file_name = image.split('/')[-1] # file_name\n",
    "    id_, gender_, race_, age_group_, age_, type_ = file_name.split('_')   # 실제 데이터의 정보\n",
    "\n",
    "    padding=20\n",
    "\n",
    "    resultImg,faceBoxes=highlightFace(faceNet,frame)\n",
    "    if not faceBoxes:\n",
    "        print(\"No face detected\")\n",
    "\n",
    "    try:\n",
    "        for faceBox in faceBoxes:\n",
    "            face=frame[max(0,faceBox[1]-padding):\n",
    "                        min(faceBox[3]+padding,frame.shape[0]-1),max(0,faceBox[0]-padding)\n",
    "                        :min(faceBox[2]+padding, frame.shape[1]-1)]\n",
    "\n",
    "            blob=cv2.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "            genderNet.setInput(blob)\n",
    "            genderPreds=genderNet.forward()\n",
    "            gender=genderList[genderPreds[0].argmax()].lower()\n",
    "\n",
    "            ageNet.setInput(blob)\n",
    "            agePreds=ageNet.forward()\n",
    "            age=ageList[agePreds[0].argmax()]\n",
    "            age_group = get_age_range(age)\n",
    "        \n",
    "        flash_data = [file_name, id_, age_, age_group_, age_group, age, gender_, gender]\n",
    "        data_all_df = data_all_df.append(pd.Series(flash_data, index=data_all_df.columns), ignore_index=True)\n",
    "    except:\n",
    "        print(\"Can't detect face\")    \n",
    "        error.append(file_name)\n",
    "    # print(gender, age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check error -> 얼굴 인식을 못하는 경우!\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "\n",
    "image = os.path.join(folder_dir, \"normal/\"+error[0])\n",
    "img2 = rgb_to_bgr(image)\n",
    "ax1.imshow(img2)\n",
    "\n",
    "image = os.path.join(folder_dir, \"normal/\"+error[1])\n",
    "img2 = rgb_to_bgr(image)\n",
    "ax2.imshow(img2)\n",
    "\n",
    "image = os.path.join(folder_dir, \"normal/\"+error[2])\n",
    "img2 = rgb_to_bgr(image)\n",
    "ax3.imshow(img2)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all_df.to_csv('age_gender_detection_normal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_check = data_all_df['age_group'] == data_all_df['age_group_pred']\n",
    "gender_check = data_all_df['gender'] == data_all_df['gender_pred']\n",
    "\n",
    "data_all_df['check_age'] = age_check.apply(lambda x:'incorrect_age' if x == False else 'correct_age')\n",
    "data_all_df['check_gender'] = gender_check.apply(lambda x:'incorrect_gender' if x == False else 'correct_gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct_age      1598\n",
       "incorrect_age    1099\n",
       "Name: check_age, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_df['check_age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct_gender      1826\n",
       "incorrect_gender     871\n",
       "Name: check_gender, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_df['check_gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = os.path.join(folder_dir, normal_img[0])\n",
    "img = rgb_to_bgr(img)\n",
    "# img = cv2.imread(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 384, 3)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = os.path.join(folder_dir, \"normal/\"+error[0])\n",
    "# img = cv2.imread(img)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8-12) 0.846 age1\n"
     ]
    }
   ],
   "source": [
    "age=ageList[agePreds[0].argmax()]\n",
    "age_pred = max(agePreds[0].round(3))\n",
    "age_group = get_age_range(age)\n",
    "print(age, age_pred, age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0-2)  :  0.0\n",
      "(4-6)  :  0.005\n",
      "(8-12)  :  0.846\n",
      "(15-20)  :  0.124\n",
      "(25-32)  :  0.01\n",
      "(38-43)  :  0.014\n",
      "(48-53)  :  0.0\n",
      "(60-100)  :  0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ageList)):\n",
    "    print(ageList[i],\" : \", agePreds[0][i].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
