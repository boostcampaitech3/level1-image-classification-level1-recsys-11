{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def rgb_to_bgr(image):\n",
    "    b, g, r = cv2.split(image)\n",
    "    image = cv2.merge([r, g, b])\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 이미지 수:  21579\n",
      "incorrect 이미지 수:  2700\n",
      "normal 이미지 수:  2700\n",
      "mask 이미지 수:  13500\n",
      "각 list 예시: \n",
      "/opt/ml/input/data/train/images/000001_female_Asian_45/incorrect_mask.jpg\n",
      "/opt/ml/input/data/train/images/000001_female_Asian_45/normal.jpg\n",
      "/opt/ml/input/data/train/images/000001_female_Asian_45/mask3.jpg\n"
     ]
    }
   ],
   "source": [
    "folder_dir = '/opt/ml/input/data/train/images'\n",
    "folder_name = os.listdir(folder_dir)\n",
    "folder_name = sorted([x for x in folder_name if '._' not in x]) # '._' 제거\n",
    "\n",
    "file_list = [[folder_name[i]+\"/\"+file for file in os.listdir(os.path.join(folder_dir,folder_name[i])) if '._' not in file and 'ipynb' not in file] for i in range(len(folder_name))]\n",
    "\n",
    "# 모든 이미지명 리스트\n",
    "all_file_list = list(chain(*file_list))\n",
    "\n",
    "# class별 이미지명 리스트\n",
    "incorrect_img = [os.path.join(folder_dir, file) for file in all_file_list if 'incorrect_mask' in file]\n",
    "normal_img = [os.path.join(folder_dir, file) for file in all_file_list if 'normal' in file]\n",
    "mask_img = [os.path.join(folder_dir, file) for file in all_file_list if 'incorrect_mask' not in file and 'normal' not in file]\n",
    "\n",
    "incorrect_img = [file for file in incorrect_img if 'crop' not in file.split('/')[-1]]\n",
    "normal_img = [file for file in normal_img if 'crop' not in file.split('/')[-1]]\n",
    "mask_img = [file for file in mask_img if 'crop' not in file.split('/')[-1]]\n",
    "\n",
    "\n",
    "print('모든 이미지 수: ', len(all_file_list))\n",
    "print('incorrect 이미지 수: ', len(incorrect_img))\n",
    "print('normal 이미지 수: ', len(normal_img))\n",
    "print('mask 이미지 수: ', len(mask_img))\n",
    "print('각 list 예시: ',incorrect_img[0], normal_img[0], mask_img[0], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSD object detector (상반신)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /opt/ml/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n",
      "/opt/ml/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "/opt/ml/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "Using cache found in /opt/ml/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SSD300(\n",
       "  (feature_extractor): ResNet(\n",
       "    (feature_extractor): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (additional_blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (loc): ModuleList(\n",
       "    (0): Conv2d(1024, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf): ModuleList(\n",
       "    (0): Conv2d(1024, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd')\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n",
    "\n",
    "ssd_model.to('cuda')\n",
    "ssd_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_cropping_top(image_list, batch_size):\n",
    "    fail = []\n",
    "    last = int(len(image_list) // batch_size)+1\n",
    "    tt_x, tt_y, tt_w, tt_h = 0, 0, 0, 0\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    for turn in range(1, last+1):\n",
    "        if turn == last:\n",
    "            inputs = [utils.prepare_input(file) for file in image_list[(turn-1)*batch_size:]]\n",
    "            print(\"last turn!\")\n",
    "        else:\n",
    "            inputs = [utils.prepare_input(file) for file in image_list[(turn-1)*batch_size:turn*batch_size]]\n",
    "            print(\"turn {}, {}\".format(turn, len(inputs)))\n",
    "                    \n",
    "        tensor = utils.prepare_tensor(inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            detections_batch = ssd_model(tensor)\n",
    "\n",
    "        results_per_input = utils.decode_results(detections_batch)\n",
    "        best_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\n",
    "\n",
    "\n",
    "        for image_idx in range(len(best_results_per_input)):\n",
    "            # Show original, denormalized image...\n",
    "            image = inputs[image_idx] / 2 + 0.5\n",
    "            \n",
    "            # ...with detections\n",
    "            bboxes, classes, confidences = best_results_per_input[image_idx]\n",
    "            img_info = image_list[image_idx+((turn-1)*batch_size)]\n",
    "            img_path, img_name = '/'.join(img_info.split('/')[:-1]), img_info.split('/')[-1]\n",
    "            src, dst = img_name.split('.')\n",
    "            \n",
    "            \n",
    "            left, bot, right, top = bboxes[0]\n",
    "            x, y, w, h = [val * 300 for val in [left, bot, right - left, top - bot]]\n",
    "            detected_face_ = image[int(y):int(y+h), int(x):int(x+w)]\n",
    "            \n",
    "            try:\n",
    "                detected_face_ = rgb_to_bgr(255*detected_face_)    \n",
    "                # cv2.imwrite(os.path.join(img_path, src+\"_cropped_top.\"+dst), detected_face_)\n",
    "                tt_x += x\n",
    "                tt_y += y\n",
    "                tt_w += w\n",
    "                tt_h += h\n",
    "            except:\n",
    "                x, y, w, h = [11.0, 30.0, 283.0, 271.0]\n",
    "                crop_face_ = image[int(y):int(y+h), int(x):int(x+w)]\n",
    "                crop_face_ = rgb_to_bgr(255*crop_face_)\n",
    "                cv2.imwrite(os.path.join(img_path, src+\"_cropped_top.\"+dst), crop_face_)\n",
    "                fail.append(img_info)\n",
    "    \n",
    "    tt_x = (tt_x//((len(image_list)-len(fail))))\n",
    "    tt_y = (tt_y//((len(image_list)-len(fail))))\n",
    "    tt_w = (tt_w//((len(image_list)-len(fail))))\n",
    "    tt_h = (tt_h//((len(image_list)-len(fail))))\n",
    "    region = [tt_x, tt_y, tt_w, tt_h]\n",
    "    \n",
    "    return region, fail\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn 1, 512\n",
      "turn 2, 512\n",
      "turn 3, 512\n",
      "turn 4, 512\n",
      "turn 5, 512\n",
      "last turn!\n"
     ]
    }
   ],
   "source": [
    "# avg_region, fail = face_cropping_top(incorrect_img, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_cropping_top_avg(image_list, batch_size):\n",
    "    last = int(len(image_list) // batch_size)+1\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    for turn in range(1, last+1):\n",
    "        if turn == last:\n",
    "            inputs = [utils.prepare_input(file) for file in image_list[(turn-1)*batch_size:]]\n",
    "            print(\"last turn!\")\n",
    "        else:\n",
    "            inputs = [utils.prepare_input(file) for file in image_list[(turn-1)*batch_size:turn*batch_size]]\n",
    "            print(\"turn {}, {}\".format(turn, len(inputs)))\n",
    "                    \n",
    "        for image_idx in range(len(inputs)):\n",
    "            img_info = image_list[image_idx+((turn-1)*batch_size)]\n",
    "            img_path, img_name = '/'.join(img_info.split('/')[:-1]), img_info.split('/')[-1]\n",
    "            src, dst = img_name.split('.')\n",
    "\n",
    "            # Show original, denormalized image...\n",
    "            image = inputs[image_idx] / 2 + 0.5\n",
    "        \n",
    "            x, y, w, h = [11.0, 30.0, 283.0, 271.0]\n",
    "            crop_face_ = image[int(y):int(y+h), int(x):int(x+w)]\n",
    "            crop_face_ = rgb_to_bgr(255*crop_face_)\n",
    "            cv2.imwrite(os.path.join(img_path, src+\"_cropped_top.\"+dst), crop_face_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cropping_top_avg(incorrect_img, 512)\n",
    "face_cropping_top_avg(normal_img, 512)\n",
    "# face_cropping_top_avg(mask_img, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fail</th>\n",
       "      <th>mask_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/opt/ml/input/data/train/images/000534_female_...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/opt/ml/input/data/train/images/000538_male_As...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/opt/ml/input/data/train/images/000561_female_...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/opt/ml/input/data/train/images/000591_female_...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/opt/ml/input/data/train/images/000735_female_...</td>\n",
       "      <td>incorrect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                fail  mask_type\n",
       "0  /opt/ml/input/data/train/images/000534_female_...  incorrect\n",
       "1  /opt/ml/input/data/train/images/000538_male_As...  incorrect\n",
       "2  /opt/ml/input/data/train/images/000561_female_...  incorrect\n",
       "3  /opt/ml/input/data/train/images/000591_female_...  incorrect\n",
       "4  /opt/ml/input/data/train/images/000735_female_...  incorrect"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fail_df = pd.DataFrame(fail, columns=['fail'])\n",
    "# fail_df['mask_type'] = 'incorrect'\n",
    "# print(len(fail_df))\n",
    "# fail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0 30.0 283.0 271.0\n"
     ]
    }
   ],
   "source": [
    "# x, y, w, h = avg_region\n",
    "# print(x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fail = list(set(fail))\n",
    "# fail_df = pd.DataFrame(fail, columns=['file'])\n",
    "# fail_df['detector'] = 'ssd_object'\n",
    "# fail_df['masks'] = img_name\n",
    "# fail_df.to_csv('top_cropping_fail_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mtcnn detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mtcnn import MTCNN\n",
    "# detector = MTCNN()\n",
    "# fail = []\n",
    "\n",
    "# for img_info in normal_img:\n",
    "#     img_path, img_name = '/'.join(img_info.split('/')[:-1]), img_info.split('/')[-1]\n",
    "#     src, dst = img_name.split('.')\n",
    "\n",
    "#     img = cv2.imread(img_info)\n",
    "#     detections = detector.detect_faces(img)\n",
    "\n",
    "#     if detections != []:\n",
    "#         for detection in detections:\n",
    "#             score = detection[\"confidence\"]\n",
    "#             if score > 0.90:\n",
    "#                 x, y, w, h = detection[\"box\"]\n",
    "#                 detected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "#             cv2.imwrite(os.path.join(img_path, src+\"_cropped.\"+dst), detected_face)\n",
    "#     else:\n",
    "#         fail.append(img_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fail))\n",
    "fail_id = [file.split('/')[-2] for file in fail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### timm mobilenet 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision.models as models\n",
    "\n",
    "# mobilenet_v2 = models.mobilenet_v2()\n",
    "# model = mobilenet_v2\n",
    "# model.eval()\n",
    "# model.to('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ssd 사용 크롭 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_ssd = pd.read_csv('detection_normal_ssd.csv')\n",
    "detection_ssd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(detection_ssd['file'])):\n",
    "    img_info = detection_ssd['file'][idx]\n",
    "    img_path, img_name = '/'.join(img_info.split('/')[:-1]), img_info.split('/')[-1]\n",
    "    src, dst = img_name.split('.')\n",
    "\n",
    "    tt = detection_ssd['region'][idx].split()\n",
    "    x, y, w, h = int(tt[1][:-1]), int(tt[3][:-1]), int(tt[5][:-1]), int(tt[7][:-1])\n",
    "    \n",
    "    image = cv2.imread(img_info)\n",
    "    detected_face = image[int(y)-5:int(y+h)+5, int(x)-5:int(x+w)+5]\n",
    "    # plt.imshow(detected_face)\n",
    "    cv2.imwrite(os.path.join(img_path, src+\"_cropped_ssd.\"+dst), detected_face)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepface TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_1 = DeepFace.detectFace(img_path = normal_img[0], target_size = (224, 224), detector_backend = backends[0])\n",
    "face_2 = DeepFace.detectFace(img_path = normal_img[0], target_size = (224, 224), detector_backend = backends[1])\n",
    "face_3 = DeepFace.detectFace(img_path = normal_img[0], target_size = (224, 224), detector_backend = backends[2])\n",
    "face_4 = DeepFace.detectFace(img_path = normal_img[0], target_size = (224, 224), detector_backend = backends[3])\n",
    "face_5 = DeepFace.detectFace(img_path = normal_img[0], target_size = (224, 224), detector_backend = backends[4])\n",
    "# face_6 = DeepFace.detectFace(img_path = normal_img[0], target_size = (224, 224), detector_backend = backends[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(7, 5, figsize=(40, 24))\n",
    "backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface', 'mediapipe']\n",
    "\n",
    "for j in range(7):\n",
    "    for i in range(5):\n",
    "        face = DeepFace.detectFace(img_path = normal_img[j], target_size = (224, 224), detector_backend = backends[i])\n",
    "        axes[j][i].imshow(face)\n",
    "        axes[j][i].set_title(backends[i])\n",
    "        axes[j][i].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(10):\n",
    "    obj = []\n",
    "    for i in range(5):\n",
    "        obj.append(DeepFace.analyze(img_path = normal_img[j], actions = ['age', 'gender'], detector_backend=backends[i]))\n",
    "    print(normal_img[j])\n",
    "    print(obj)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
